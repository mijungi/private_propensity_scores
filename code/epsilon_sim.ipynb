{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of $\\epsilon$ on Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1090bfb50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from misc.agm import calibrateAnalyticGaussianMechanism\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. experiments, no. draws of z, no. samples, dim, X\n",
    "ne = 100\n",
    "nd = 1\n",
    "ns = 2000\n",
    "dim = 50\n",
    "\n",
    "# draw ne separate ns samples\n",
    "X_std = 3\n",
    "X_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([X_std], dtype=torch.float64)\n",
    ")\n",
    "X  = [X_dist.sample((ns, dim)).squeeze() for i in range(ne)]\n",
    "\n",
    "# restrict X to ||x||_2 \\leq 1 to fit assumption for each experiment\n",
    "X = torch.stack([X[i] / X[i].norm(dim=1).max() for i in range(ne)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of points used to fit log reg\n",
    "nf = 1000\n",
    "\n",
    "# privacy parameters\n",
    "# epses = [0.01, 0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "epses = [0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "delta = 1e-6\n",
    "\n",
    "# regularisation coefficient\n",
    "reg_co = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating Y, differentiate between Y_0 and Y_1 with true treatment effect tau\n",
    "# Y = beta^T X + 0.1 Z\n",
    "# Y_1 = Y + tau, Y_0 = Y\n",
    "beta_std = 1\n",
    "beta_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0], dtype=torch.float64), \n",
    "    torch.tensor([beta_std], dtype=torch.float64)\n",
    ")\n",
    "beta = beta_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "\n",
    "# true treatment effect tau\n",
    "tau = 0.1\n",
    "\n",
    "# generate Y\n",
    "Y_std = 0.1\n",
    "Y = torch.einsum('kl,ijk->ij',beta,X) + Y_std * torch.randn(ne, ns, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating T\n",
    "# T = exp(-T_w^T X + b)\n",
    "T_std = 1\n",
    "T_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([T_std], dtype=torch.float64)\n",
    ")\n",
    "T_w = T_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "T_b = 0\n",
    "\n",
    "# generate T\n",
    "prob_vec = torch.sigmoid(torch.einsum('kl,ijk->ij', T_w, X) + T_b)\n",
    "T = torch.bernoulli(prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(torch.nn.Module):\n",
    "    '''\n",
    "    Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(Log_Reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(D_in, D_out, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPTW_PPS(\n",
    "    X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf\n",
    "):\n",
    "    '''\n",
    "    average treatment effect with inverse probability of treatment weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    # sgd step size\n",
    "    step_size = 0.01\n",
    "\n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "\n",
    "    # reshape estimate splits for later\n",
    "    Y0_s1 = Y0_s1.reshape(ne, 1, est_split)\n",
    "    Y1_s1 = Y1_s1.reshape(ne, 1, est_split)\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "\n",
    "    # instantiate ne different models\n",
    "    models = [Log_Reg(dim, 1) for i in range(ne)]\n",
    "    # set model parameters to float64\n",
    "    [model.double() for model in models]\n",
    "\n",
    "    # define loss (binary cross entropy)\n",
    "    loss = torch.nn.BCELoss()\n",
    "\n",
    "    # define optimisers\n",
    "    optimisers = [\n",
    "        torch.optim.SGD(\n",
    "            models[i].parameters(),\n",
    "            lr=step_size,\n",
    "            weight_decay=reg_co,\n",
    "        )\n",
    "        for i in range(ne)\n",
    "    ]\n",
    "\n",
    "    # train models\n",
    "    for t in range(1000):\n",
    "        preds = [\n",
    "            models[i](X_s0[i]).squeeze() for i in range(ne)\n",
    "        ]\n",
    "        losses = [\n",
    "            loss(preds[i], T_s0[i]) for i in range(ne)\n",
    "        ]\n",
    "        [opt.zero_grad for opt in optimisers]\n",
    "        [loss.backward() for loss in losses]\n",
    "        [opt.step() for opt in optimisers]\n",
    "\n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    \n",
    "    # initialise e dictionary\n",
    "    e = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [models[i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # perturb model and get relevant quantities\n",
    "    for eps in epses:\n",
    "        # define sensitivity for log reg\n",
    "        s_w = 2.0 / (fit_split * reg_co)\n",
    "\n",
    "        # define sigma for log reg\n",
    "        sigma = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_w / eps)\n",
    "        sigma_2 = sigma ** 2\n",
    "\n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma = calibrateAnalyticGaussianMechanism(eps, delta, s_w)\n",
    "#         sigma_2 = sigma ** 2\n",
    "\n",
    "        # define z distribution for log reg\n",
    "        z_dist = torch.distributions.normal.Normal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.tensor([sigma], dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        # draw z for log reg\n",
    "        z_vecs = z_dist.sample(\n",
    "            (ne, nd, dim)\n",
    "        ).reshape(ne, nd, dim)\n",
    "\n",
    "        # create temp models\n",
    "        models_ = [copy.deepcopy(models) for i in range(nd)]\n",
    "\n",
    "        # initialise list for privatised estimated propensity scores\n",
    "        pi_hats[eps] = []\n",
    "\n",
    "        # perturb weights with z_vecs\n",
    "        for i in range(ne):\n",
    "            for j in range(nd):\n",
    "                model_temp = models_[j][i]\n",
    "                model_temp.linear.weight.data.add_(\n",
    "                    z_vecs[i, j, :]\n",
    "                )\n",
    "                pi_hats[eps].append(\n",
    "                    model_temp(X_s1[i]).squeeze()\n",
    "                )\n",
    "\n",
    "        # reshape stacked privatised estimated propensity scores as ne * nd\n",
    "        pi_hats[eps] = torch.stack(pi_hats[eps]).reshape(ne, nd, est_split)\n",
    "        \n",
    "        # max of abs of Y1_s1 / propensity score for each experiment\n",
    "        max_abs_Y1_s1_div_ps = torch.max(\n",
    "            torch.abs(Y1_s1) / pi_hats[eps], 2\n",
    "        )[0]\n",
    "        # max of abs of Y0_s1 / (1 - propensity score) for each experiment\n",
    "        max_abs_Y0_s1_div_1_m_ps = torch.max(\n",
    "            torch.abs(Y1_s1) / (1 - pi_hats[eps]), 2\n",
    "        )[0]\n",
    "        # hstack max_abs_Y_s1_div_ps and max_abs_Y_s1_div_1_m_ps\n",
    "        max_abs_all = torch.cat(\n",
    "            (max_abs_Y1_s1_div_ps, max_abs_Y0_s1_div_1_m_ps), \n",
    "            1,\n",
    "        )\n",
    "        \n",
    "        # replace inf/nan with 1e20 for stability\n",
    "        max_abs_all[torch.isfinite(max_abs_all) == 0] = 1e20\n",
    "            \n",
    "        # define sensitivity for estimation\n",
    "        s_e = 1 / (ns - nf) * 2 * torch.max(max_abs_all, 1)[0]\n",
    "        \n",
    "        # define sigma for estimation\n",
    "        sigma_e = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_e / eps)\n",
    "        sigma_e_2 = sigma_e ** 2\n",
    "        \n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma_e = calibrateAnalyticGaussianMechanism(eps, delta, s_e)\n",
    "#         sigma_e_2 = sigma_e ** 2\n",
    "\n",
    "        # define e distribution for estimation\n",
    "        e_dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.diag(sigma_e)\n",
    "        )\n",
    "\n",
    "        # draw e for estimation\n",
    "        e[eps] = e_dist.sample().reshape(ne)\n",
    "    \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and std of means of ERM + private ERM\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # means and std of means of privatised te_hats\n",
    "    te_hats_p = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1.squeeze() / prob_vec[idx, s1]\n",
    "        - Y0_s1.squeeze() / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "                \n",
    "    for key in pi_hats.keys():\n",
    "        if key != 0:\n",
    "            # empirical estimates\n",
    "            # reduce_mean from (ne, nd, est_split) tensor to (ne * nd, 1) matrix\n",
    "            te_hats_ = torch.mean(\n",
    "                Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]), \n",
    "                [1, 2],\n",
    "            )\n",
    "        else:\n",
    "            # empirical estimate for noiseless case\n",
    "            # reduce_mean from (ne, est_split) tensor to (ne , 1) matrix\n",
    "            te_hats_ = torch.mean(\n",
    "                Y1_s1.squeeze() / pi_hats[key] - Y0_s1.squeeze() / (1 - pi_hats[key]),\n",
    "                1,\n",
    "            )\n",
    "        te_hats['means'].append(\n",
    "            te_hats_.detach().numpy()\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            te_hats_.std().detach().numpy()\n",
    "        )\n",
    "        try:\n",
    "            te_hats_p_ = te_hats_ + e[key]\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_p_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_p_.std().detach().numpy()\n",
    "            )\n",
    "        except KeyError:\n",
    "            # fill first row for later\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_.std().detach().numpy()\n",
    "            )\n",
    "        \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_p['means'] = np.array(te_hats_p['means'])\n",
    "    te_hats_p['stds'] = np.array(te_hats_p['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname, tau, te_hats, te_hats_p, epses, ne):\n",
    "    '''\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau}_\\epsilon and \\hat{\\tau}_\\epsilon_n\n",
    "    '''\n",
    "    \n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats['means'][1:])):\n",
    "        # \\hat{\\tau}_\\epsilon\n",
    "        te_hats['means'][1:][i][\n",
    "            np.isnan(te_hats['means'][1:][i])\n",
    "        ] = -tau\n",
    "        # \\hat{\\tau}_\\epsilon_n\n",
    "        te_hats_p['means'][1:][i][\n",
    "            np.isnan(te_hats_p['means'][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats['means'][0])\n",
    "\n",
    "    # compute probabilities\n",
    "    probs_te_hats = [\n",
    "        sum(sgn_tau_hat != np.sign(te_hats['means'][1:][i])) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    probs_all = [\n",
    "        sum(abs(sgn_tau_hat + np.sign(te_hats['means'][1:][i]) + np.sign(te_hats_p['means'][1:][i])) != 3) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    # plot figure\n",
    "    y_name = \"P(sgn($\\\\hat{\\\\tau}$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_\\\\epsilon$))\"\n",
    "    y_name_all = \"P(sgn($\\\\hat{\\\\tau}$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_{\\\\epsilon_{N}}$))\"\n",
    "        \n",
    "    ind = np.arange(len(epses))\n",
    "    width = 0.35     \n",
    "        \n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 5))\n",
    "    ax.bar(ind, probs_te_hats, width, color='g', label=y_name)\n",
    "    ax.bar(ind+width, probs_all, width, color='b', label=y_name_all)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"P(sign change) against $\\epsilon$ for $\\\\tau$ = {}\".format(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "#     ax.set_ylabel(y_name, fontsize=18)\n",
    "    ax.set_xlabel(\"privacy loss ($\\epsilon$)\", fontsize=18)\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels([str(i) for i in epses])\n",
    "    ax.tick_params(labelsize=16)\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.pdf',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_te(figname, te, te_hats, te_hats_analytic, epses, eps_pos, tau,):\n",
    "    '''\n",
    "    plot the true treatment effect, ERM, private ERM treatment effect\n",
    "    \n",
    "    eps_pos is the position of the first eps to plot frrom\n",
    "    '''\n",
    "\n",
    "    # get means and stds\n",
    "    te_hat = np.mean([te_hats['means'][0]], 1)\n",
    "    te_hat_std = np.std([te_hats['means'][0]])\n",
    "    te_hat_z = np.mean(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_z_std = np.std(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_mu = np.mean(te_hats_analytic['means'], 1)[eps_pos:]\n",
    "    te_hat_mu_std = (\n",
    "        np.std(te_hats_analytic['means'], 1)[eps_pos:] + np.mean(te_hats_analytic['stds'], 1)[eps_pos:]\n",
    "    )\n",
    "\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te['mean']] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='magenta',\n",
    "        label=\"Truth\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te_hat] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='red',\n",
    "        label=\"ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z,\n",
    "        marker='x',\n",
    "        color='blue',\n",
    "        label=\"Empirical Private ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu,\n",
    "        marker='d',\n",
    "        color='green',\n",
    "        label=\"Analytical Private ERM\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat + te_hat_std,\n",
    "        te_hat - te_hat_std,\n",
    "        facecolor='red',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z + te_hat_z_std,\n",
    "        te_hat_z - te_hat_z_std,\n",
    "        facecolor='blue',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu + te_hat_mu_std,\n",
    "        te_hat_mu - te_hat_mu_std,\n",
    "        facecolor='green',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"True, ERM, Empirical Private ERM and Analytical Private ERM ATE against $\\epsilon$\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_xlabel(\"$\\epsilon$\", fontsize=18)\n",
    "    # set legend position\n",
    "    if tau > 0:\n",
    "        ax.legend(fontsize=16, loc=1)\n",
    "    else:\n",
    "        ax.legend(fontsize=16, loc=4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname + '.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\tau = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# te, te_hats, te_hats_analytic = IPTW_PPS(X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf)\n",
    "te, te_hats, te_hats_p = IPTW_PPS(X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_tau_'+str(tau)+'_epses_flip_prob', tau, te_hats, te_hats_p, epses, ne)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
