{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of $\\epsilon$ on Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11d2a7910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from misc.agm import calibrateAnalyticGaussianMechanism\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. experiments, no. draws of z, no. samples, dim, X\n",
    "ne = 100\n",
    "nd = 1\n",
    "ns = 2000\n",
    "dim = 50\n",
    "\n",
    "# draw ne separate ns samples\n",
    "X_std = 3\n",
    "X_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([X_std], dtype=torch.float64)\n",
    ")\n",
    "X  = [X_dist.sample((ns, dim)).squeeze() for i in range(ne)]\n",
    "\n",
    "# restrict X to ||x||_2 \\leq 1 to fit assumption for each experiment\n",
    "X = torch.stack([X[i] / X[i].norm(dim=1).max() for i in range(ne)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of points used to fit log reg\n",
    "nf = 1000\n",
    "\n",
    "# privacy parameters\n",
    "epses = [0.01, 0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "# epses = [0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "delta = 1e-6\n",
    "\n",
    "# regularisation coefficient\n",
    "reg_co = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating Y, differentiate between Y_0 and Y_1 with true treatment effect tau\n",
    "# Y = beta^T X + 0.1 Z\n",
    "# Y_1 = Y + tau, Y_0 = Y\n",
    "beta_std = 1\n",
    "beta_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0], dtype=torch.float64), \n",
    "    torch.tensor([beta_std], dtype=torch.float64)\n",
    ")\n",
    "beta = beta_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "\n",
    "# true treatment effect tau\n",
    "tau = 2\n",
    "\n",
    "# generate Y\n",
    "Y_std = 0.1\n",
    "Y = torch.einsum('kl,ijk->ij',beta,X) + Y_std * torch.randn(ne, ns, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating T\n",
    "# T = exp(-T_w^T X + b)\n",
    "T_std = 1\n",
    "T_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([T_std], dtype=torch.float64)\n",
    ")\n",
    "T_w = T_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "T_b = 0\n",
    "\n",
    "# generate T\n",
    "prob_vec = torch.sigmoid(torch.einsum('kl,ijk->ij', T_w, X) + T_b)\n",
    "T = torch.bernoulli(prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(torch.nn.Module):\n",
    "    '''\n",
    "    Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(Log_Reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(D_in, D_out, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPTW_PPS(\n",
    "    X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf\n",
    "):\n",
    "    '''\n",
    "    average treatment effect with inverse probability of treatment weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    # sgd step size\n",
    "    step_size = 0.01\n",
    "\n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "\n",
    "    # reshape estimate splits for later\n",
    "    Y0_s1 = Y0_s1.reshape(ne, 1, est_split)\n",
    "    Y1_s1 = Y1_s1.reshape(ne, 1, est_split)\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "\n",
    "    # instantiate ne different models\n",
    "    models = [Log_Reg(dim, 1) for i in range(ne)]\n",
    "    # set model parameters to float64\n",
    "    [model.double() for model in models]\n",
    "\n",
    "    # define loss (binary cross entropy)\n",
    "    loss = torch.nn.BCELoss()\n",
    "\n",
    "    # define optimisers\n",
    "    optimisers = [\n",
    "        torch.optim.SGD(\n",
    "            models[i].parameters(),\n",
    "            lr=step_size,\n",
    "            weight_decay=reg_co,\n",
    "        )\n",
    "        for i in range(ne)\n",
    "    ]\n",
    "\n",
    "    # train models\n",
    "    for t in range(1000):\n",
    "        preds = [\n",
    "            models[i](X_s0[i]).squeeze() for i in range(ne)\n",
    "        ]\n",
    "        losses = [\n",
    "            loss(preds[i], T_s0[i]) for i in range(ne)\n",
    "        ]\n",
    "        [opt.zero_grad for opt in optimisers]\n",
    "        [loss.backward() for loss in losses]\n",
    "        [opt.step() for opt in optimisers]\n",
    "\n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    \n",
    "    # initialise e dictionary\n",
    "    e = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [models[i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # perturb model and get relevant quantities\n",
    "    for eps in epses:\n",
    "        # define sensitivity for log reg\n",
    "        s_w = 2.0 / (fit_split * reg_co)\n",
    "\n",
    "        # define sigma for log reg\n",
    "        sigma = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_w / eps)\n",
    "        sigma_2 = sigma ** 2\n",
    "\n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma = calibrateAnalyticGaussianMechanism(eps, delta, s_w)\n",
    "#         sigma_2 = sigma ** 2\n",
    "\n",
    "        # define z distribution for log reg\n",
    "        z_dist = torch.distributions.normal.Normal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.tensor([sigma], dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        # draw z for log reg\n",
    "        z_vecs = z_dist.sample(\n",
    "            (ne, nd, dim)\n",
    "        ).reshape(ne, nd, dim)\n",
    "\n",
    "        # create temp models\n",
    "        models_ = [copy.deepcopy(models) for i in range(nd)]\n",
    "\n",
    "        # initialise list for privatised estimated propensity scores\n",
    "        pi_hats[eps] = []\n",
    "\n",
    "        # perturb weights with z_vecs\n",
    "        for i in range(ne):\n",
    "            for j in range(nd):\n",
    "                model_temp = models_[j][i]\n",
    "                model_temp.linear.weight.data.add_(\n",
    "                    z_vecs[i, j, :]\n",
    "                )\n",
    "                pi_hats[eps].append(\n",
    "                    model_temp(X_s1[i]).squeeze()\n",
    "                )\n",
    "\n",
    "        # reshape stacked privatised estimated propensity scores as ne * nd\n",
    "        pi_hats[eps] = torch.stack(pi_hats[eps]).reshape(ne, nd, est_split)\n",
    "        \n",
    "        # max of abs of Y_s1 / propensity score for each experiment\n",
    "        max_abs_Y_s1_div_ps = torch.max(\n",
    "            torch.abs(Y1_s1 + Y0_s1) / pi_hats[eps], 2\n",
    "        )[0]\n",
    "        # max of abs of Y_s1 / (1 - propensity score) for each experiment\n",
    "        max_abs_Y_s1_div_1_m_ps = torch.max(\n",
    "            torch.abs(Y1_s1 + Y0_s1) / (1 - pi_hats[eps]), 2\n",
    "        )[0]\n",
    "        # hstack max_abs_Y_s1_div_ps and max_abs_Y_s1_div_1_m_ps\n",
    "        max_abs_all = torch.cat(\n",
    "            (max_abs_Y_s1_div_ps, max_abs_Y_s1_div_1_m_ps), \n",
    "            1,\n",
    "        )\n",
    "        \n",
    "        # replace inf/nan with 1e20 for stability\n",
    "        max_abs_all[torch.isfinite(max_abs_all) == 0] = 1e20\n",
    "            \n",
    "        # define sensitivity for estimation\n",
    "        s_e = 1 / (ns - nf) * 2 * torch.max(max_abs_all, 1)[0]\n",
    "        \n",
    "        # define sigma for estimation\n",
    "        sigma_e = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_e / eps)\n",
    "        sigma_e_2 = sigma_e ** 2\n",
    "        \n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma_e = calibrateAnalyticGaussianMechanism(eps, delta, s_e)\n",
    "#         sigma_e_2 = sigma_e ** 2\n",
    "\n",
    "        # define e distribution for estimation\n",
    "        e_dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.diag(sigma_e)\n",
    "        )\n",
    "\n",
    "        # draw e for estimation\n",
    "        e[eps] = e_dist.sample().reshape(ne)\n",
    "    \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and std of means of ERM + private ERM\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # means and std of means of privatised te_hats\n",
    "    te_hats_p = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1.squeeze() / prob_vec[idx, s1]\n",
    "        - Y0_s1.squeeze() / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "                \n",
    "    for key in pi_hats.keys():\n",
    "        if key != 0:\n",
    "            # empirical estimates\n",
    "            # reduce_mean from (ne, nd, est_split) tensor to (ne * nd, 1) matrix\n",
    "            te_hats_ = torch.mean(\n",
    "                Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]), \n",
    "                [1, 2],\n",
    "            )\n",
    "        else:\n",
    "            # empirical estimate for noiseless case\n",
    "            # reduce_mean from (ne, est_split) tensor to (ne , 1) matrix\n",
    "            te_hats_ = torch.mean(\n",
    "                Y1_s1.squeeze() / pi_hats[key] - Y0_s1.squeeze() / (1 - pi_hats[key]),\n",
    "                1,\n",
    "            )\n",
    "        te_hats['means'].append(\n",
    "            te_hats_.detach().numpy()\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            te_hats_.std().detach().numpy()\n",
    "        )\n",
    "        try:\n",
    "            te_hats_p_ = te_hats_ + e[key]\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_p_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_p_.std().detach().numpy()\n",
    "            )\n",
    "        except KeyError:\n",
    "            # fill first row for later\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_.std().detach().numpy()\n",
    "            )\n",
    "        \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_p['means'] = np.array(te_hats_p['means'])\n",
    "    te_hats_p['stds'] = np.array(te_hats_p['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname, tau, te_hats, te_hats_p, epses, ne):\n",
    "    '''\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau}_\\epsilon and \\hat{\\tau}_\\epsilon_n\n",
    "    '''\n",
    "    \n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats['means'][1:])):\n",
    "        # \\hat{\\tau}_\\epsilon\n",
    "        te_hats['means'][1:][i][\n",
    "            np.isnan(te_hats['means'][1:][i])\n",
    "        ] = -tau\n",
    "        # \\hat{\\tau}_\\epsilon_n\n",
    "        te_hats_p['means'][1:][i][\n",
    "            np.isnan(te_hats_p['means'][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats['means'][0])\n",
    "\n",
    "    # compute probabilities\n",
    "    probs_te_hats = [\n",
    "        sum(sgn_tau_hat != np.sign(te_hats['means'][1:][i])) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    probs_all = [\n",
    "        sum(abs(sgn_tau_hat + np.sign(te_hats['means'][1:][i]) + np.sign(te_hats_p['means'][1:][i])) != 3) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    # plot figure\n",
    "    y_name = \"P(sgn($\\\\hat{\\\\tau}$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_\\\\epsilon$))\"\n",
    "    y_name_all = \"P(sgn($\\\\hat{\\\\tau}$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_{\\\\epsilon_{N}}$))\"\n",
    "        \n",
    "    ind = np.arange(len(epses))\n",
    "    width = 0.35     \n",
    "        \n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 5))\n",
    "    ax.bar(ind, probs_te_hats, width, color='g', label=y_name)\n",
    "    ax.bar(ind+width, probs_all, width, color='b', label=y_name_all)\n",
    "\n",
    "    ax.set_title(\n",
    "        y_name_all\n",
    "        + \" against $\\epsilon$ for $\\\\tau$ = {}\".format(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "#     ax.set_ylabel(y_name, fontsize=18)\n",
    "    ax.set_xlabel(\"privacy loss ($\\epsilon$)\", fontsize=18)\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels([str(i) for i in epses])\n",
    "    ax.tick_params(labelsize=16)\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.pdf',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_te(figname, te, te_hats, te_hats_analytic, epses, eps_pos, tau,):\n",
    "    '''\n",
    "    plot the true treatment effect, ERM, private ERM treatment effect\n",
    "    \n",
    "    eps_pos is the position of the first eps to plot frrom\n",
    "    '''\n",
    "\n",
    "    # get means and stds\n",
    "    te_hat = np.mean([te_hats['means'][0]], 1)\n",
    "    te_hat_std = np.std([te_hats['means'][0]])\n",
    "    te_hat_z = np.mean(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_z_std = np.std(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_mu = np.mean(te_hats_analytic['means'], 1)[eps_pos:]\n",
    "    te_hat_mu_std = (\n",
    "        np.std(te_hats_analytic['means'], 1)[eps_pos:] + np.mean(te_hats_analytic['stds'], 1)[eps_pos:]\n",
    "    )\n",
    "\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te['mean']] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='magenta',\n",
    "        label=\"Truth\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te_hat] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='red',\n",
    "        label=\"ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z,\n",
    "        marker='x',\n",
    "        color='blue',\n",
    "        label=\"Empirical Private ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu,\n",
    "        marker='d',\n",
    "        color='green',\n",
    "        label=\"Analytical Private ERM\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat + te_hat_std,\n",
    "        te_hat - te_hat_std,\n",
    "        facecolor='red',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z + te_hat_z_std,\n",
    "        te_hat_z - te_hat_z_std,\n",
    "        facecolor='blue',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu + te_hat_mu_std,\n",
    "        te_hat_mu - te_hat_mu_std,\n",
    "        facecolor='green',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"True, ERM, Empirical Private ERM and Analytical Private ERM ATE against $\\epsilon$\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_xlabel(\"$\\epsilon$\", fontsize=18)\n",
    "    # set legend position\n",
    "    if tau > 0:\n",
    "        ax.legend(fontsize=16, loc=1)\n",
    "    else:\n",
    "        ax.legend(fontsize=16, loc=4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname + '.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\tau = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# te, te_hats, te_hats_analytic = IPTW_PPS(X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf)\n",
    "te, te_hats, te_hats_p = IPTW_PPS(X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_tau_'+str(tau)+'_epses_flip_prob', tau, te_hats, te_hats_p, epses, ne)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
