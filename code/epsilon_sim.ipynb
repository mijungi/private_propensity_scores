{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of $\\epsilon$ on Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12adb9310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.special import erf\n",
    "import torch\n",
    "\n",
    "from misc.agm import calibrateAnalyticGaussianMechanism\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. experiments, no. samples, dim, X\n",
    "ne = 500\n",
    "ns = 2000\n",
    "dim = 50\n",
    "\n",
    "# true treatment effect tau\n",
    "tau = 2\n",
    "\n",
    "# draw ne separate ns samples\n",
    "X_std = 3\n",
    "X_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([X_std], dtype=torch.float64)\n",
    ")\n",
    "X  = [X_dist.sample((ns, dim)).squeeze() for i in range(ne)]\n",
    "\n",
    "# restrict X to ||x||_2 \\leq 1 to fit assumption for each experiment\n",
    "X = torch.stack([X[i] / X[i].norm(dim=1).max() for i in range(ne)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of points used to fit log reg\n",
    "nf = 1000\n",
    "\n",
    "# privacy parameters\n",
    "epses = [0, 0.01, 0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "# epses = [0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "delta = torch.tensor(1e-6)\n",
    "\n",
    "# regularisation coefficient\n",
    "reg_co = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating Y, differentiate between Y_0 and Y_1 with true treatment effect tau\n",
    "# Y = beta^T X + 0.1 Z\n",
    "# Y_1 = Y + tau, Y_0 = Y\n",
    "beta_std = 1\n",
    "beta_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0], dtype=torch.float64), \n",
    "    torch.tensor([beta_std], dtype=torch.float64)\n",
    ")\n",
    "beta = beta_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "\n",
    "# generate Y\n",
    "Y_std = 0.1\n",
    "Y = torch.einsum('kl,ijk->ij',beta,X) + Y_std * torch.randn(ne, ns, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating T\n",
    "# T = exp(-T_w^T X + b)\n",
    "T_std = 1\n",
    "T_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([T_std], dtype=torch.float64)\n",
    ")\n",
    "T_w = T_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "T_b = 0\n",
    "\n",
    "# generate T\n",
    "prob_vec = torch.sigmoid(torch.einsum('kl,ijk->ij', T_w, X) + T_b)\n",
    "T = torch.bernoulli(prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(torch.nn.Module):\n",
    "    '''\n",
    "    Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(Log_Reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(D_in, D_out, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPW_PPS_Out(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf):\n",
    "    '''\n",
    "    average treatment effect with inverse propensity weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    # sgd step size\n",
    "    step_size = 0.01\n",
    "\n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for expm in range(ne):\n",
    "        X = X_s0[expm]\n",
    "        T = T_s0[expm][:, None]\n",
    "        model = Log_Reg(dim, 1).double()\n",
    "        opt = torch.optim.LBFGS(model.parameters(), max_iter=100)\n",
    "\n",
    "        # define first-order oracle for lbfgs\n",
    "        def closure():\n",
    "            if torch.is_grad_enabled():\n",
    "                opt.zero_grad()\n",
    "            outputs = model(X)\n",
    "            for weights in model.parameters():\n",
    "                loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, T) + 0.5 * reg_co * weights.norm(2).pow(2)\n",
    "            if loss.requires_grad:\n",
    "                loss.backward()\n",
    "            return loss\n",
    "\n",
    "        opt.step(closure)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    \n",
    "    # initialise e dictionary\n",
    "    e = {}\n",
    "    \n",
    "    # intialise sigma dictionary\n",
    "    sig_d = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [models[i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # perturb model and get relevant quantities\n",
    "    for eps in epses[1:]:\n",
    "        # define sensitivity for log reg\n",
    "        s_w = 2.0 / (fit_split * reg_co)\n",
    "\n",
    "        # define sigma for log reg\n",
    "        sigma = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_w / (eps / 2))\n",
    "        sigma_2 = sigma ** 2\n",
    "\n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma = calibrateAnalyticGaussianMechanism(eps, delta, s_w)\n",
    "#         sigma_2 = sigma ** 2\n",
    "\n",
    "        # define z distribution for log reg\n",
    "        z_dist = torch.distributions.normal.Normal(\n",
    "            torch.tensor(0.0, dtype=torch.float64),\n",
    "            torch.tensor(sigma, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        # draw z for log reg\n",
    "        z_vecs = z_dist.sample((ne, dim))\n",
    "\n",
    "        # create temp models\n",
    "        models_ = copy.deepcopy(models)\n",
    "\n",
    "        # initialise list for privatised estimated propensity scores\n",
    "        pi_hats[eps] = []\n",
    "\n",
    "        # perturb weights with z_vecs\n",
    "        for i in range(ne):\n",
    "            model_temp = models_[i]\n",
    "            model_temp.linear.weight.data.add_(\n",
    "                z_vecs[i]\n",
    "            )\n",
    "            pi_hats[eps].append(\n",
    "                model_temp(X_s1[i]).squeeze()\n",
    "            )\n",
    "\n",
    "        # reshape stacked privatised estimated propensity scores\n",
    "        pi_hats[eps] = torch.stack(pi_hats[eps])\n",
    "                        \n",
    "        # max of abs of Y1_s1 / propensity score for each experiment\n",
    "        max_abs_Y1_s1_div_ps = torch.max(\n",
    "            torch.abs(Y1_s1) / ((ns - nf) * pi_hats[eps]), 1\n",
    "        )[0]\n",
    "        \n",
    "        # max of abs of Y0_s1 / (1 - propensity score) for each experiment\n",
    "        max_abs_Y0_s1_div_1_m_ps = torch.max(\n",
    "            torch.abs(Y0_s1) / ((ns - nf) * (1 - pi_hats[eps])), 1\n",
    "        )[0]\n",
    "        \n",
    "        # hstack max_abs_Y_s1_div_ps and max_abs_Y_s1_div_1_m_ps\n",
    "        max_abs_all = torch.stack(\n",
    "            (max_abs_Y1_s1_div_ps, max_abs_Y0_s1_div_1_m_ps), 1\n",
    "        )\n",
    "        \n",
    "        # replace inf/nan with 1e20 for stability\n",
    "        max_abs_all[torch.isfinite(max_abs_all) == 0] = 1e20\n",
    "            \n",
    "        # define sensitivity for estimation\n",
    "        s_e = 2 * torch.max(max_abs_all, 1)[0]\n",
    "        \n",
    "        # define sigma for estimation\n",
    "        sigma_e = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_e / (eps / 2))\n",
    "        sig_d[eps] = sigma_e.detach().numpy()\n",
    "        sigma_e_2 = sigma_e ** 2\n",
    "        \n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma_e = calibrateAnalyticGaussianMechanism(eps, delta, s_e)\n",
    "#         sigma_e_2 = sigma_e ** 2\n",
    "\n",
    "        # define e distribution for estimation\n",
    "        e_dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.diag(sigma_e)\n",
    "        )\n",
    "\n",
    "        # draw e for estimation\n",
    "        e[eps] = e_dist.sample().reshape(ne)\n",
    "    \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and std of means of ERM + private ERM\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # means and std of means of privatised te_hats\n",
    "    te_hats_p = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1 / prob_vec[idx, s1] - Y0_s1 / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "                \n",
    "    for key in pi_hats.keys():\n",
    "        # empirical estimate for noiseless case\n",
    "        # reduce_mean from (ne, est_split) tensor to (ne , 1) matrix\n",
    "        te_hats_ = torch.mean(\n",
    "            Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]),\n",
    "            1,\n",
    "        )\n",
    "        te_hats['means'].append(\n",
    "            te_hats_.detach().numpy()\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            te_hats_.std().detach().numpy()\n",
    "        )\n",
    "        try:\n",
    "            te_hats_p_ = te_hats_ + e[key]\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_p_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_p_.std().detach().numpy()\n",
    "            )\n",
    "        except KeyError:\n",
    "            # fill first row for later\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_.std().detach().numpy()\n",
    "            )\n",
    "        \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_p['means'] = np.array(te_hats_p['means'])\n",
    "    te_hats_p['stds'] = np.array(te_hats_p['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_p, sig_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPW_PPS_Obj(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf):\n",
    "    '''\n",
    "    average treatment effect with inverse propensity weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    # objective perturbation constants\n",
    "    L = 1 # see from derivation, also http://proceedings.mlr.press/v32/jain14.pdf\n",
    "    R2 = 1 # as norm is bounded by 1\n",
    "    c = 0.25\n",
    "    \n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "\n",
    "    z_dist = torch.distributions.normal.Normal(\n",
    "                torch.tensor(0.0, dtype=torch.double),\n",
    "                torch.tensor(1.0, dtype=torch.double),\n",
    "                )\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    for eps in epses:\n",
    "        models[eps] = []\n",
    "        for expm in range(ne):\n",
    "            X = X_s0[expm]\n",
    "            T = T_s0[expm][:, None]\n",
    "            model = Log_Reg(dim, 1).double()\n",
    "            opt = torch.optim.LBFGS(model.parameters(), max_iter=100)\n",
    "            if eps > 0: \n",
    "                b = torch.sqrt((4 * (L * R2) ** 2 * (torch.log(1 / delta) + eps / 2)) / ((eps / 2) ** 2)) * z_dist.sample((dim, 1))\n",
    "                # b = torch.sqrt((8 * (torch.log(2. / delta) + 4 * eps)) / (eps ** 2)) * z_dist.sample((dim, 1))\n",
    "            else:\n",
    "                b = torch.zeros((dim, 1)).double()\n",
    "            \n",
    "            # define first-order oracle for lbfgs\n",
    "            def closure():\n",
    "                if torch.is_grad_enabled():\n",
    "                    opt.zero_grad()\n",
    "                outputs = model(X)\n",
    "                if eps > 0:\n",
    "                    for weights in model.parameters():\n",
    "                        reg_noise = 1 / nf * torch.matmul(weights, b) + 0.5 * reg_co * weights.norm(2).pow(2)\n",
    "                        # reg_noise = 1 / nf * torch.matmul(weights, b) + 0.5 * (2 * c * X_std / (eps * nf) + reg_co) * weights.norm(2).pow(2)\n",
    "                else:\n",
    "                    for weights in model.parameters():\n",
    "                        reg_noise = 0.5 * reg_co * weights.norm(2).pow(2)\n",
    "                loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, T) + reg_noise\n",
    "                if loss.requires_grad:\n",
    "                    loss.backward()\n",
    "                return loss\n",
    "            \n",
    "            opt.step(closure)\n",
    "\n",
    "            models[eps].append(model)\n",
    "      \n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    \n",
    "    # initialise e dictionary\n",
    "    e = {}\n",
    "    \n",
    "    # intialise sigma dictionary\n",
    "    sig_d = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [models[0][i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    for eps in epses[1:]:\n",
    "        # get perturbed propensity scores\n",
    "        pi_hats[eps] = torch.stack(\n",
    "            [models[eps][i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "        )\n",
    "                \n",
    "        # max of abs of Y1_s1 / propensity score for each experiment\n",
    "        max_abs_Y1_s1_div_ps = torch.max(\n",
    "            torch.abs(Y1_s1) / ((ns - nf) * pi_hats[eps]), 1\n",
    "        )[0]\n",
    "                \n",
    "        # max of abs of Y0_s1 / (1 - propensity score) for each experiment\n",
    "        max_abs_Y0_s1_div_1_m_ps = torch.max(\n",
    "            torch.abs(Y0_s1) / ((ns - nf) * (1 - pi_hats[eps])), 1\n",
    "        )[0]\n",
    "        \n",
    "        # hstack max_abs_Y_s1_div_ps and max_abs_Y_s1_div_1_m_ps\n",
    "        max_abs_all = torch.stack(\n",
    "            (max_abs_Y1_s1_div_ps, max_abs_Y0_s1_div_1_m_ps), 1\n",
    "        )\n",
    "                \n",
    "        # replace inf/nan with 1e20 for stability\n",
    "        max_abs_all[torch.isfinite(max_abs_all) == 0] = 1e20\n",
    "            \n",
    "        # define sensitivity for estimation\n",
    "        s_e = 2 * torch.max(max_abs_all, 1)[0]\n",
    "        \n",
    "        # define sigma for estimation\n",
    "        sigma_e = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_e / (eps / 2))\n",
    "        sig_d[eps] = sigma_e.detach().numpy()\n",
    "        sigma_e_2 = sigma_e ** 2\n",
    "        \n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma_e = calibrateAnalyticGaussianMechanism(eps, delta, s_e)\n",
    "#         sigma_e_2 = sigma_e ** 2\n",
    "\n",
    "        # define e distribution for estimation\n",
    "        e_dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.diag(sigma_e)\n",
    "        )\n",
    "\n",
    "        # draw e for estimation\n",
    "        e[eps] = e_dist.sample().reshape(ne)\n",
    "    \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and std of means of ERM + private ERM\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # means and std of means of privatised te_hats\n",
    "    te_hats_p = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1 / prob_vec[idx, s1] - Y0_s1 / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "                \n",
    "    for key in pi_hats.keys():\n",
    "        # reduce_mean from (ne, est_split) tensor to (ne, 1) matrix\n",
    "        te_hats_ = torch.mean(\n",
    "            Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]), \n",
    "            1,\n",
    "        )\n",
    "        te_hats['means'].append(\n",
    "            te_hats_.detach().numpy()\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            te_hats_.std().detach().numpy()\n",
    "        )\n",
    "        try:\n",
    "            te_hats_p_ = te_hats_ + e[key]\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_p_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_p_.std().detach().numpy()\n",
    "            )\n",
    "        except KeyError:\n",
    "            # fill first row for later\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_.std().detach().numpy()\n",
    "            )\n",
    "        \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_p['means'] = np.array(te_hats_p['means'])\n",
    "    te_hats_p['stds'] = np.array(te_hats_p['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_p, sig_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname, tau, te_hats, te_hats_p, epses, ne):\n",
    "    '''\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau}_\\epsilon and \\hat{\\tau}_\\epsilon_n\n",
    "    '''\n",
    "    \n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats['means'][1:])):\n",
    "        # \\hat{\\tau}_\\epsilon\n",
    "        te_hats['means'][1:][i][\n",
    "            np.isnan(te_hats['means'][1:][i])\n",
    "        ] = -tau\n",
    "        # \\hat{\\tau}_\\epsilon_n\n",
    "        te_hats_p['means'][1:][i][\n",
    "            np.isnan(te_hats_p['means'][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats['means'][0])\n",
    "\n",
    "    # compute probabilities\n",
    "    probs_te_hats = [\n",
    "        sum(sgn_tau_hat != np.sign(te_hats['means'][1:][i])) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    probs_all = [\n",
    "#         sum(abs(sgn_tau_hat + np.sign(te_hats['means'][1:][i]) + np.sign(te_hats_p['means'][1:][i])) != 3) / ne\n",
    "        sum((sgn_tau_hat != np.sign(te_hats['means'][1:][i])).astype('int') + \n",
    "            (sgn_tau_hat != np.sign(te_hats_p['means'][1:][i])).astype('int') == 2) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    print(probs_te_hats)\n",
    "    print(probs_all)\n",
    "    \n",
    "    # plot figure\n",
    "    y_name = \"P(sgn($\\\\hat{\\\\tau}_n$) $\\\\neq$ sgn($\\\\hat{\\\\tau}$))\"\n",
    "    y_name_all = \"P(sgn($\\\\hat{\\\\tau}_n^\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau})$, sgn($\\\\hat{\\\\tau}_n$)$\\\\neq$ sgn($\\\\hat{\\\\tau}$))\"\n",
    "        \n",
    "    ind = np.arange(len(epses))\n",
    "    width = 0.35     \n",
    "        \n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 6))\n",
    "    ax.bar(ind, probs_te_hats, width, color='g', label=y_name)\n",
    "    ax.bar(ind+width, probs_all, width, color='b', label=y_name_all)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"P(sign change) against $\\epsilon$ for $\\\\tau$ = {}\".format(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.set_xlabel(\"privacy loss ($\\epsilon$)\", fontsize=18)\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels([str(i) for i in epses])\n",
    "    ax.tick_params(labelsize=16)\n",
    "    \n",
    "    ax.legend(fontsize=16)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.pdf',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_erf(figname, tau, te_hats, te_hats_p, epses, sig_d):\n",
    "    \"\"\"\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau}_n^\\epsilon w.r.t erf(|\\hat{\\tau}_n}| / sigma_n)\n",
    "    \"\"\"\n",
    "\n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats[\"means\"][1:])):\n",
    "        # \\hat{\\tau}_n\n",
    "        te_hats[\"means\"][1:][i][\n",
    "            np.isnan(te_hats[\"means\"][1:][i])\n",
    "        ] = -tau\n",
    "        # \\hat{\\tau}_n^\\epsilon\n",
    "        te_hats_p[\"means\"][1:][i][\n",
    "            np.isnan(te_hats_p[\"means\"][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats[\"means\"][0])\n",
    "\n",
    "    sgn_list = []\n",
    "    val_list = []\n",
    "\n",
    "    for i in range(len(epses)):\n",
    "        # get sigma\n",
    "        sigma = sig_d[epses[i]]\n",
    "\n",
    "        # get sgn and val for eps whose sgn(\\hat{\\tau}_n) != sgn(\\hat{\\tau})\n",
    "        sgn_flip_idx = (\n",
    "            np.sign(te_hats[\"means\"][i + 1]) != sgn_tau_hat\n",
    "        )\n",
    "\n",
    "        # get tau_hat_n of disagreements\n",
    "        sgn_flip_te_hat = te_hats[\"means\"][i + 1][\n",
    "            sgn_flip_idx\n",
    "        ]\n",
    "\n",
    "        abs_sgn_flip_te_hat_div_sigma = (\n",
    "            np.abs(sgn_flip_te_hat) / sigma[sgn_flip_idx]\n",
    "        )\n",
    "\n",
    "        sgn_list += (\n",
    "            np.sign(te_hats_p[\"means\"][i + 1][sgn_flip_idx])\n",
    "            != sgn_tau_hat[sgn_flip_idx]\n",
    "        ).tolist()\n",
    "\n",
    "        # add all val where sgn_tau_hat_n != sgn_tau_hat\n",
    "        val_list += abs_sgn_flip_te_hat_div_sigma.tolist()\n",
    "\n",
    "    sgn_list = np.array(sgn_list)\n",
    "    val_list = np.array(val_list)\n",
    "\n",
    "    # set # of bins\n",
    "    bins = np.linspace(0, 0.40, 20)\n",
    "\n",
    "    # bin w.r.t to vals where sgn(\\hat{\\tau}_n^\\epsilon) != sgn(\\hat{\\tau})\n",
    "    hist1, bins1 = np.histogram(\n",
    "        erf(val_list[sgn_list == 1]), bins=bins\n",
    "    )\n",
    "\n",
    "    binWidth1 = bins1[1] - bins1[0]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    lab_1 = (\n",
    "        \"# of sgn($\\\\hat{\\\\tau}_n$) $\\\\neq$ sgn($\\\\hat{\\\\tau}) = $\"\n",
    "        + str(len(val_list))\n",
    "    )\n",
    "    lab_2 = (\n",
    "        \"# of sgn($\\\\hat{\\\\tau}_n^\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau}) = $\"\n",
    "        + str(len(val_list[sgn_list == 1]))\n",
    "    )\n",
    "\n",
    "    ax.bar(\n",
    "        bins1[:-1],\n",
    "        (\n",
    "            hist1 / len(val_list)\n",
    "        ),  # divide by number of times where sgn(\\hat{\\tau}_n) != sgn(\\hat{\\tau}) to get probability\n",
    "        binWidth1,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"P(sgn($\\\\hat{\\\\tau}_n^\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau}$) | sgn($\\\\hat{\\\\tau}_n$) $\\\\neq$ sgn($\\\\hat{\\\\tau}$)) for $\\\\tau$ = \"\n",
    "        + str(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.tick_params(labelsize=16)\n",
    "    ax.set_xlabel(\n",
    "        \"erf(|$\\\\hat{\\\\tau}_n$|/$\\\\sigma_n$)\", fontsize=18\n",
    "    )\n",
    "\n",
    "    empty_leg = Rectangle((0, 0), 0, 0, alpha=0.0)\n",
    "    ax.legend(\n",
    "        [empty_leg, empty_leg],\n",
    "        [lab_1, lab_2],\n",
    "        handlelength=0,\n",
    "        fontsize=14,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname + \"_\" + str(tau) + \".pdf\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_te(figname, te, te_hats, te_hats_analytic, epses, eps_pos, tau,):\n",
    "    '''\n",
    "    plot the true treatment effect, ERM, private ERM treatment effect\n",
    "    \n",
    "    eps_pos is the position of the first eps to plot frrom\n",
    "    '''\n",
    "\n",
    "    # get means and stds\n",
    "    te_hat = np.mean([te_hats['means'][0]], 1)\n",
    "    te_hat_std = np.std([te_hats['means'][0]])\n",
    "    te_hat_z = np.mean(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_z_std = np.std(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_mu = np.mean(te_hats_analytic['means'], 1)[eps_pos:]\n",
    "    te_hat_mu_std = (\n",
    "        np.std(te_hats_analytic['means'], 1)[eps_pos:] + np.mean(te_hats_analytic['stds'], 1)[eps_pos:]\n",
    "    )\n",
    "\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te['mean']] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='magenta',\n",
    "        label=\"Truth\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te_hat] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='red',\n",
    "        label=\"ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z,\n",
    "        marker='x',\n",
    "        color='blue',\n",
    "        label=\"Empirical Private ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu,\n",
    "        marker='d',\n",
    "        color='green',\n",
    "        label=\"Analytical Private ERM\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat + te_hat_std,\n",
    "        te_hat - te_hat_std,\n",
    "        facecolor='red',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z + te_hat_z_std,\n",
    "        te_hat_z - te_hat_z_std,\n",
    "        facecolor='blue',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu + te_hat_mu_std,\n",
    "        te_hat_mu - te_hat_mu_std,\n",
    "        facecolor='green',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"True, ERM, Empirical Private ERM and Analytical Private ERM ATE against $\\epsilon$\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_xlabel(\"$\\epsilon$\", fontsize=18)\n",
    "    # set legend position\n",
    "    if tau > 0:\n",
    "        ax.legend(fontsize=16, loc=1)\n",
    "    else:\n",
    "        ax.legend(fontsize=16, loc=4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname + '.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\tau = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sikai/.pyenv/versions/3.7.6/lib/python3.7/site-packages/ipykernel_launcher.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "te, te_hats, te_hats_p, sig_d = IPW_PPS_Out(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.974, 0.124, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.974, 0.12, 0.036, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_tau_'+str(tau)+'_epses_flip_prob', tau, te_hats, te_hats_p, epses[1:], ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "te, te_hats, te_hats_p, sig_d = IPW_PPS_Obj(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.406, 0.058, 0.006, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.406, 0.036, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_tau_'+str(tau)+'_epses_flip_prob_obj', tau, te_hats, te_hats_p, epses[1:], ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_hist_erf('hist_erf', tau, te_hats, te_hats_p, epses, sig_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
