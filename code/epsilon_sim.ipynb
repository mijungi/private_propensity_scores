{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of $\\epsilon$ on Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12c937cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.special import erf\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from misc.agm import calibrateAnalyticGaussianMechanism\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. experiments, no. samples, dim, X\n",
    "ne = 500\n",
    "ns = 2000\n",
    "dim = 50\n",
    "\n",
    "# true treatment effect tau\n",
    "tau = 0.1\n",
    "\n",
    "# draw ne separate ns samples\n",
    "X_std = 3\n",
    "X_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([X_std], dtype=torch.float64)\n",
    ")\n",
    "X  = [X_dist.sample((ns, dim)).squeeze() for i in range(ne)]\n",
    "\n",
    "# restrict X to ||x||_2 \\leq 1 to fit assumption for each experiment\n",
    "X = torch.stack([X[i] / X[i].norm(dim=1).max() for i in range(ne)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of points used to fit log reg\n",
    "nf = 1000\n",
    "\n",
    "# privacy parameters\n",
    "# epses = [0, 0.01, 0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "epses = [0, 0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "delta = torch.tensor(1e-6)\n",
    "\n",
    "# regularisation coefficient\n",
    "reg_co = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating Y, differentiate between Y_0 and Y_1 with true treatment effect tau\n",
    "# Y = beta^T X + 0.1 Z\n",
    "# Y_1 = Y + tau, Y_0 = Y\n",
    "beta_std = 1\n",
    "beta_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0], dtype=torch.float64), \n",
    "    torch.tensor([beta_std], dtype=torch.float64)\n",
    ")\n",
    "beta = beta_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "\n",
    "# generate Y\n",
    "Y_std = 0.1\n",
    "Y = torch.einsum('kl,ijk->ij',beta,X) + Y_std * torch.randn(ne, ns, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating T\n",
    "# T = exp(-T_w^T X + b)\n",
    "T_std = 1\n",
    "T_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([T_std], dtype=torch.float64)\n",
    ")\n",
    "T_w = T_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "T_b = 0\n",
    "\n",
    "# generate T\n",
    "prob_vec = torch.sigmoid(torch.einsum('kl,ijk->ij', T_w, X) + T_b)\n",
    "T = torch.bernoulli(prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(torch.nn.Module):\n",
    "    '''\n",
    "    Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(Log_Reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(D_in, D_out, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPW_PPS_Out(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf):\n",
    "    '''\n",
    "    average treatment effect with inverse propensity weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for expm in range(ne):\n",
    "        X = Variable(X_s0[expm], requires_grad=True)\n",
    "        T = Variable(T_s0[expm][:, None])\n",
    "        model = Log_Reg(dim, 1).double()\n",
    "        opt = torch.optim.LBFGS(model.parameters(), max_iter=100)\n",
    "\n",
    "        # define first-order oracle for lbfgs\n",
    "        def closure():\n",
    "            if torch.is_grad_enabled():\n",
    "                opt.zero_grad()\n",
    "            outputs = model(X)\n",
    "            for weights in model.parameters():\n",
    "                loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, T) + 0.5 * reg_co * weights.norm(2).pow(2)\n",
    "            if loss.requires_grad:\n",
    "                loss.backward()\n",
    "            return loss\n",
    "\n",
    "        opt.step(closure)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    \n",
    "    # initialise e dictionary\n",
    "    e = {}\n",
    "    \n",
    "    # intialise sigma dictionary\n",
    "    sig_d = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [models[i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # perturb model and get relevant quantities\n",
    "    for eps in epses[1:]:\n",
    "        # define sensitivity for log reg\n",
    "        s_w = 2.0 / (fit_split * reg_co)\n",
    "\n",
    "        # define sigma for log reg\n",
    "        sigma = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_w / (eps / 2))\n",
    "        sigma_2 = sigma ** 2\n",
    "\n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma = calibrateAnalyticGaussianMechanism(eps, delta, s_w)\n",
    "#         sigma_2 = sigma ** 2\n",
    "\n",
    "        # define z distribution for log reg\n",
    "        z_dist = torch.distributions.normal.Normal(\n",
    "            torch.tensor(0.0, dtype=torch.float64),\n",
    "            torch.tensor(sigma, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        # draw z for log reg\n",
    "        z_vecs = z_dist.sample((ne, dim))\n",
    "\n",
    "        # create temp models\n",
    "        models_ = copy.deepcopy(models)\n",
    "\n",
    "        # initialise list for privatised estimated propensity scores\n",
    "        pi_hats[eps] = []\n",
    "\n",
    "        # perturb weights with z_vecs\n",
    "        for i in range(ne):\n",
    "            model_temp = models_[i]\n",
    "            model_temp.linear.weight.data.add_(\n",
    "                z_vecs[i]\n",
    "            )\n",
    "            pi_hats[eps].append(\n",
    "                model_temp(X_s1[i]).squeeze()\n",
    "            )\n",
    "\n",
    "        # reshape stacked privatised estimated propensity scores\n",
    "        pi_hats[eps] = torch.stack(pi_hats[eps])\n",
    "                        \n",
    "        # max of abs of Y1_s1 / propensity score for each experiment\n",
    "        max_abs_Y1_s1_div_ps = torch.max(\n",
    "            torch.abs(Y1_s1) / ((ns - nf) * pi_hats[eps]), 1\n",
    "        )[0]\n",
    "        \n",
    "        # max of abs of Y0_s1 / (1 - propensity score) for each experiment\n",
    "        max_abs_Y0_s1_div_1_m_ps = torch.max(\n",
    "            torch.abs(Y0_s1) / ((ns - nf) * (1 - pi_hats[eps])), 1\n",
    "        )[0]\n",
    "        \n",
    "        # hstack max_abs_Y_s1_div_ps and max_abs_Y_s1_div_1_m_ps\n",
    "        max_abs_all = torch.stack(\n",
    "            (max_abs_Y1_s1_div_ps, max_abs_Y0_s1_div_1_m_ps), 1\n",
    "        )\n",
    "        \n",
    "        # replace inf/nan with 1e20 for stability\n",
    "        max_abs_all[torch.isfinite(max_abs_all) == 0] = 1e20\n",
    "            \n",
    "        # define sensitivity for estimation\n",
    "        s_e = 2 * torch.max(max_abs_all, 1)[0]\n",
    "        \n",
    "        # define sigma for estimation\n",
    "        sigma_e = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_e / (eps / 2))\n",
    "        sig_d[eps] = sigma_e.detach().numpy()\n",
    "        sigma_e_2 = sigma_e ** 2\n",
    "        \n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma_e = calibrateAnalyticGaussianMechanism(eps, delta, s_e)\n",
    "#         sigma_e_2 = sigma_e ** 2\n",
    "\n",
    "        # define e distribution for estimation\n",
    "        e_dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.diag(sigma_e)\n",
    "        )\n",
    "\n",
    "        # draw e for estimation\n",
    "        e[eps] = e_dist.sample().reshape(ne)\n",
    "    \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and std of means of ERM + private ERM\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # means and std of means of privatised te_hats\n",
    "    te_hats_p = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1 / prob_vec[idx, s1] - Y0_s1 / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "                \n",
    "    for key in pi_hats.keys():\n",
    "        # empirical estimate for noiseless case\n",
    "        # reduce_mean from (ne, est_split) tensor to (ne , 1) matrix\n",
    "        te_hats_ = torch.mean(\n",
    "            Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]),\n",
    "            1,\n",
    "        )\n",
    "        te_hats['means'].append(\n",
    "            te_hats_.detach().numpy()\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            te_hats_.std().detach().numpy()\n",
    "        )\n",
    "        try:\n",
    "            te_hats_p_ = te_hats_ + e[key]\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_p_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_p_.std().detach().numpy()\n",
    "            )\n",
    "        except KeyError:\n",
    "            # fill first row for later\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_.std().detach().numpy()\n",
    "            )\n",
    "        \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_p['means'] = np.array(te_hats_p['means'])\n",
    "    te_hats_p['stds'] = np.array(te_hats_p['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_p, sig_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPW_PPS_Obj(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf):\n",
    "    '''\n",
    "    average treatment effect with inverse propensity weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    # objective perturbation constants\n",
    "    L = 1 # see from derivation, also http://proceedings.mlr.press/v32/jain14.pdf\n",
    "    R2 = 1 # as norm is bounded by 1\n",
    "    c = 0.25\n",
    "    \n",
    "    \n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "\n",
    "    z_dist = torch.distributions.normal.Normal(\n",
    "                torch.tensor(0.0, dtype=torch.double),\n",
    "                torch.tensor(1.0, dtype=torch.double),\n",
    "                )\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    for eps in epses:\n",
    "        models[eps] = []\n",
    "        for expm in range(ne):\n",
    "            # follows from http://proceedings.mlr.press/v23/kifer12/kifer12.pdf,\n",
    "            # hessian is bounded by 0.25 * max_eig_val, see https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L4.pdf\n",
    "            eig_val, _ = torch.symeig(torch.matmul(X_s0[expm].T, X_s0[expm]))\n",
    "            Delta = 2 * torch.max(eig_val) / (eps / 2)\n",
    "            X = Variable(X_s0[expm], requires_grad=True)\n",
    "            T = Variable(T_s0[expm][:, None].double())\n",
    "            model = Log_Reg(dim, 1).double()\n",
    "            opt = torch.optim.LBFGS(model.parameters(), max_iter=100)\n",
    "            if eps > 0: \n",
    "                reg_co_ = reg_co\n",
    "                # zeta =< 1 for logistic loss\n",
    "                b = torch.sqrt((8 * (torch.log(2. / delta) + 4 * eps / 2)) / ((eps / 2) ** 2)) * z_dist.sample((dim, 1))\n",
    "            \n",
    "            # define first-order oracle for lbfgs\n",
    "            def closure():\n",
    "                if torch.is_grad_enabled():\n",
    "                    opt.zero_grad()\n",
    "                outputs = model(X)\n",
    "                if eps > 0:\n",
    "                    for weights in model.parameters():\n",
    "                        reg_noise = (1 / nf) * torch.matmul(weights, b) + 0.5 * (reg_co_ + 0.25 * Delta / nf) * weights.pow(2).sum(1) \n",
    "                else:\n",
    "                    for weights in model.parameters():\n",
    "                        reg_noise = 0.5 * reg_co * weights.norm(2).pow(2)\n",
    "                loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, T) + reg_noise\n",
    "                if loss.requires_grad:\n",
    "                    loss.backward()\n",
    "                return loss\n",
    "            \n",
    "            opt.step(closure)\n",
    "\n",
    "            models[eps].append(model)\n",
    "      \n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    \n",
    "    # initialise e dictionary\n",
    "    e = {}\n",
    "    \n",
    "    # intialise sigma dictionary\n",
    "    sig_d = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [models[0][i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    for eps in epses[1:]:\n",
    "        # get perturbed propensity scores\n",
    "        pi_hats[eps] = torch.stack(\n",
    "            [models[eps][i](X_s1[i]).squeeze() for i in range(ne)]\n",
    "        )\n",
    "                \n",
    "        # max of abs of Y1_s1 / propensity score for each experiment\n",
    "        max_abs_Y1_s1_div_ps = torch.max(\n",
    "            torch.abs(Y1_s1) / ((ns - nf) * pi_hats[eps]), 1\n",
    "        )[0]\n",
    "                \n",
    "        # max of abs of Y0_s1 / (1 - propensity score) for each experiment\n",
    "        max_abs_Y0_s1_div_1_m_ps = torch.max(\n",
    "            torch.abs(Y0_s1) / ((ns - nf) * (1 - pi_hats[eps])), 1\n",
    "        )[0]\n",
    "        \n",
    "        # hstack max_abs_Y_s1_div_ps and max_abs_Y_s1_div_1_m_ps\n",
    "        max_abs_all = torch.stack(\n",
    "            (max_abs_Y1_s1_div_ps, max_abs_Y0_s1_div_1_m_ps), 1\n",
    "        )\n",
    "                \n",
    "        # replace inf/nan with 1e20 for stability\n",
    "        max_abs_all[torch.isfinite(max_abs_all) == 0] = 1e20\n",
    "            \n",
    "        # define sensitivity for estimation\n",
    "        s_e = 2 * torch.max(max_abs_all, 1)[0]\n",
    "        \n",
    "        # define sigma for estimation\n",
    "        sigma_e = np.sqrt(\n",
    "            2 * np.log(1.25 / delta) + 1e-10\n",
    "        ) * (s_e / (eps / 2))\n",
    "        sig_d[eps] = sigma_e.detach().numpy()\n",
    "        sigma_e_2 = sigma_e ** 2\n",
    "        \n",
    "#         # analytic gaussian mechanism\n",
    "#         sigma_e = calibrateAnalyticGaussianMechanism(eps, delta, s_e)\n",
    "#         sigma_e_2 = sigma_e ** 2\n",
    "\n",
    "        # define e distribution for estimation\n",
    "        e_dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.diag(sigma_e)\n",
    "        )\n",
    "\n",
    "        # draw e for estimation\n",
    "        e[eps] = e_dist.sample().reshape(ne)\n",
    "    \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and std of means of ERM + private ERM\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # means and std of means of privatised te_hats\n",
    "    te_hats_p = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1 / prob_vec[idx, s1] - Y0_s1 / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "                \n",
    "    for key in pi_hats.keys():\n",
    "        # reduce_mean from (ne, est_split) tensor to (ne, 1) matrix\n",
    "        te_hats_ = torch.mean(\n",
    "            Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]), \n",
    "            1,\n",
    "        )\n",
    "        te_hats['means'].append(\n",
    "            te_hats_.detach().numpy()\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            te_hats_.std().detach().numpy()\n",
    "        )\n",
    "        try:\n",
    "            te_hats_p_ = te_hats_ + e[key]\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_p_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_p_.std().detach().numpy()\n",
    "            )\n",
    "        except KeyError:\n",
    "            # fill first row for later\n",
    "            te_hats_p['means'].append(\n",
    "                te_hats_.detach().numpy()\n",
    "            )\n",
    "            te_hats_p['stds'].append(\n",
    "                te_hats_.std().detach().numpy()\n",
    "            )\n",
    "        \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_p['means'] = np.array(te_hats_p['means'])\n",
    "    te_hats_p['stds'] = np.array(te_hats_p['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_p, sig_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname, tau, te_hats, te_hats_p, epses, ne):\n",
    "    '''\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau}_\\epsilon and \\hat{\\tau}_\\epsilon_n\n",
    "    '''\n",
    "    \n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats['means'][1:])):\n",
    "        # \\hat{\\tau}_\\epsilon\n",
    "        te_hats['means'][1:][i][\n",
    "            np.isnan(te_hats['means'][1:][i])\n",
    "        ] = -tau\n",
    "        # \\hat{\\tau}_\\epsilon_n\n",
    "        te_hats_p['means'][1:][i][\n",
    "            np.isnan(te_hats_p['means'][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats['means'][0])\n",
    "\n",
    "    # compute probabilities\n",
    "    probs_te_hats = [\n",
    "        sum(sgn_tau_hat != np.sign(te_hats['means'][1:][i])) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    probs_all = [\n",
    "#         sum(abs(sgn_tau_hat + np.sign(te_hats['means'][1:][i]) + np.sign(te_hats_p['means'][1:][i])) != 3) / ne\n",
    "        sum((sgn_tau_hat != np.sign(te_hats['means'][1:][i])).astype('int') + \n",
    "            (sgn_tau_hat != np.sign(te_hats_p['means'][1:][i])).astype('int') == 2) / ne\n",
    "        for i in range(len(te_hats['means'][1:]))\n",
    "    ]\n",
    "    \n",
    "    print(probs_te_hats)\n",
    "    print(probs_all)\n",
    "    \n",
    "    # plot figure\n",
    "    y_name = \"P(sgn($\\\\hat{\\\\tau}_n$) $\\\\neq$ sgn($\\\\hat{\\\\tau}$))\"\n",
    "    y_name_all = \"P(sgn($\\\\hat{\\\\tau}_n^\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau})$, sgn($\\\\hat{\\\\tau}_n$)$\\\\neq$ sgn($\\\\hat{\\\\tau}$))\"\n",
    "        \n",
    "    ind = np.arange(len(epses))\n",
    "    width = 0.35     \n",
    "        \n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 6))\n",
    "    ax.bar(ind, probs_te_hats, width, color='g', label=y_name)\n",
    "    ax.bar(ind+width, probs_all, width, color='b', label=y_name_all)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"P(sign change) against $\\epsilon$ for $\\\\tau$ = {}\".format(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.set_xlabel(\"privacy loss ($\\epsilon$)\", fontsize=18)\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels([str(i) for i in epses])\n",
    "    ax.tick_params(labelsize=16)\n",
    "    \n",
    "    ax.legend(fontsize=16)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.pdf',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_erf(figname, tau, te_hats, te_hats_p, epses, sig_d):\n",
    "    \"\"\"\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau}_n^\\epsilon w.r.t erf(|\\hat{\\tau}_n}| / sigma_n)\n",
    "    \"\"\"\n",
    "\n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats[\"means\"][1:])):\n",
    "        # \\hat{\\tau}_n\n",
    "        te_hats[\"means\"][1:][i][\n",
    "            np.isnan(te_hats[\"means\"][1:][i])\n",
    "        ] = -tau\n",
    "        # \\hat{\\tau}_n^\\epsilon\n",
    "        te_hats_p[\"means\"][1:][i][\n",
    "            np.isnan(te_hats_p[\"means\"][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats[\"means\"][0])\n",
    "\n",
    "    sgn_list = []\n",
    "    val_list = []\n",
    "\n",
    "    for i in range(len(epses)):\n",
    "        # get sigma\n",
    "        sigma = sig_d[epses[i]]\n",
    "\n",
    "        # get sgn and val for eps whose sgn(\\hat{\\tau}_n) != sgn(\\hat{\\tau})\n",
    "        sgn_flip_idx = (\n",
    "            np.sign(te_hats[\"means\"][i + 1]) != sgn_tau_hat\n",
    "        )\n",
    "\n",
    "        # get tau_hat_n of disagreements\n",
    "        sgn_flip_te_hat = te_hats[\"means\"][i + 1][\n",
    "            sgn_flip_idx\n",
    "        ]\n",
    "\n",
    "        abs_sgn_flip_te_hat_div_sigma = (\n",
    "            np.abs(sgn_flip_te_hat) / sigma[sgn_flip_idx]\n",
    "        )\n",
    "\n",
    "        sgn_list += (\n",
    "            np.sign(te_hats_p[\"means\"][i + 1][sgn_flip_idx])\n",
    "            != sgn_tau_hat[sgn_flip_idx]\n",
    "        ).tolist()\n",
    "\n",
    "        # add all val where sgn_tau_hat_n != sgn_tau_hat\n",
    "        val_list += abs_sgn_flip_te_hat_div_sigma.tolist()\n",
    "\n",
    "    sgn_list = np.array(sgn_list)\n",
    "    val_list = np.array(val_list)\n",
    "\n",
    "    # set # of bins\n",
    "    bins = np.linspace(0, 0.40, 20)\n",
    "\n",
    "    # bin w.r.t to vals where sgn(\\hat{\\tau}_n^\\epsilon) != sgn(\\hat{\\tau})\n",
    "    hist1, bins1 = np.histogram(\n",
    "        erf(val_list[sgn_list == 1]), bins=bins\n",
    "    )\n",
    "\n",
    "    binWidth1 = bins1[1] - bins1[0]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    lab_1 = (\n",
    "        \"# of sgn($\\\\hat{\\\\tau}_n$) $\\\\neq$ sgn($\\\\hat{\\\\tau}) = $\"\n",
    "        + str(len(val_list))\n",
    "    )\n",
    "    lab_2 = (\n",
    "        \"# of sgn($\\\\hat{\\\\tau}_n^\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau}) = $\"\n",
    "        + str(len(val_list[sgn_list == 1]))\n",
    "    )\n",
    "\n",
    "    ax.bar(\n",
    "        bins1[:-1],\n",
    "        (\n",
    "            hist1 / len(val_list)\n",
    "        ),  # divide by number of times where sgn(\\hat{\\tau}_n) != sgn(\\hat{\\tau}) to get probability\n",
    "        binWidth1,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"P(sgn($\\\\hat{\\\\tau}_n^\\\\epsilon$) $\\\\neq$ sgn($\\\\hat{\\\\tau}$) | sgn($\\\\hat{\\\\tau}_n$) $\\\\neq$ sgn($\\\\hat{\\\\tau}$)) for $\\\\tau$ = \"\n",
    "        + str(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.tick_params(labelsize=16)\n",
    "    ax.set_xlabel(\n",
    "        \"erf(|$\\\\hat{\\\\tau}_n$|/$\\\\sigma_n$)\", fontsize=18\n",
    "    )\n",
    "\n",
    "    empty_leg = Rectangle((0, 0), 0, 0, alpha=0.0)\n",
    "    ax.legend(\n",
    "        [empty_leg, empty_leg],\n",
    "        [lab_1, lab_2],\n",
    "        handlelength=0,\n",
    "        fontsize=14,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname + \"_\" + str(tau) + \".pdf\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_te(figname, te, te_hats, te_hats_analytic, epses, eps_pos, tau,):\n",
    "    '''\n",
    "    plot the true treatment effect, ERM, private ERM treatment effect\n",
    "    \n",
    "    eps_pos is the position of the first eps to plot frrom\n",
    "    '''\n",
    "\n",
    "    # get means and stds\n",
    "    te_hat = np.mean([te_hats['means'][0]], 1)\n",
    "    te_hat_std = np.std([te_hats['means'][0]])\n",
    "    te_hat_z = np.mean(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_z_std = np.std(te_hats['means'][1:], 1)[eps_pos:]\n",
    "    te_hat_mu = np.mean(te_hats_analytic['means'], 1)[eps_pos:]\n",
    "    te_hat_mu_std = (\n",
    "        np.std(te_hats_analytic['means'], 1)[eps_pos:] + np.mean(te_hats_analytic['stds'], 1)[eps_pos:]\n",
    "    )\n",
    "\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te['mean']] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='magenta',\n",
    "        label=\"Truth\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        [te_hat] * len(epses[eps_pos:]),\n",
    "        marker='o',\n",
    "        color='red',\n",
    "        label=\"ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z,\n",
    "        marker='x',\n",
    "        color='blue',\n",
    "        label=\"Empirical Private ERM\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu,\n",
    "        marker='d',\n",
    "        color='green',\n",
    "        label=\"Analytical Private ERM\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat + te_hat_std,\n",
    "        te_hat - te_hat_std,\n",
    "        facecolor='red',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_z + te_hat_z_std,\n",
    "        te_hat_z - te_hat_z_std,\n",
    "        facecolor='blue',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        epses[eps_pos:],\n",
    "        te_hat_mu + te_hat_mu_std,\n",
    "        te_hat_mu - te_hat_mu_std,\n",
    "        facecolor='green',\n",
    "        alpha=0.25,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"True, ERM, Empirical Private ERM and Analytical Private ERM ATE against $\\epsilon$\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_xlabel(\"$\\epsilon$\", fontsize=18)\n",
    "    # set legend position\n",
    "    if tau > 0:\n",
    "        ax.legend(fontsize=16, loc=1)\n",
    "    else:\n",
    "        ax.legend(fontsize=16, loc=4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname + '.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\tau = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sikai/.pyenv/versions/3.7.6/lib/python3.7/site-packages/ipykernel_launcher.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "te, te_hats, te_hats_p, sig_d = IPW_PPS_Out(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.428, 0.42, 0.274, 0.074, 0.0, 0.0, 0.0]\n",
      "[0.386, 0.278, 0.138, 0.04, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_tau_'+str(tau)+'_epses_flip_prob', tau, te_hats, te_hats_p, epses[1:], ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "te, te_hats, te_hats_p, sig_d = IPW_PPS_Obj(X, T, prob_vec, Y, tau, epses, delta, reg_co, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.084, 0.08, 0.032, 0.008, 0.002, 0.0, 0.0]\n",
      "[0.034, 0.052, 0.026, 0.006, 0.002, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_tau_'+str(tau)+'_epses_flip_prob_obj', tau, te_hats, te_hats_p, epses[1:], ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_hist_erf('hist_erf', tau, te_hats, te_hats_p, epses, sig_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
