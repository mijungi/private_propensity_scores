{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of $\\alpha$/$\\epsilon$ on Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1112d1bd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no.experiments, no. folds, no. samples, dim, X\n",
    "ne = 100\n",
    "k = 10\n",
    "ns = 1200\n",
    "dim = 50\n",
    "\n",
    "# draw ne separate ns samples\n",
    "X_std = 3\n",
    "X_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([X_std], dtype=torch.float64)\n",
    ")\n",
    "X = [X_dist.sample((ns, dim)).squeeze() for i in range(ne)]\n",
    "\n",
    "# restrict X to ||x||_2 \\leq 1 to fit assumption for each experiment\n",
    "X = torch.stack([X[i] / X[i].norm(dim=1).max() for i in range(ne)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of points used to fit log reg\n",
    "nf = 1000\n",
    "\n",
    "# privacy parameters\n",
    "alphas = [1.01, 1.5, 2, 4, 6]\n",
    "# epses obtained from calc_total_epsilon.ipynb in misc\n",
    "epses = [0.92, 1.35, 3.08, 4.58, 8.81]\n",
    "\n",
    "# regularisation coefficient\n",
    "reg_co = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating Y, differentiate between Y_0 and Y_1 with true treatment effect tau\n",
    "# Y = beta^T X + 0.1 Z\n",
    "# Y_1 = Y + tau, Y_0 = Y\n",
    "beta_std = 1\n",
    "beta_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0], dtype=torch.float64), \n",
    "    torch.tensor([beta_std], dtype=torch.float64)\n",
    ")\n",
    "beta = beta_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "\n",
    "# true treatment effect tau\n",
    "tau = 0.1\n",
    "\n",
    "# generate Y\n",
    "rand_mult = 0.1\n",
    "Y = torch.einsum('kl,ijk->ij',beta,X) + rand_mult * torch.randn(ne, ns, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating T\n",
    "# T = exp(-T_w^T X + b)\n",
    "T_std = 1\n",
    "T_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), \n",
    "    torch.tensor([T_std], dtype=torch.float64)\n",
    ")\n",
    "T_w = T_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "T_b = 0\n",
    "\n",
    "# generate T \\in {0, 1}\n",
    "prob_vec = torch.sigmoid(torch.einsum('kl,ijk->ij', T_w, X) + T_b)\n",
    "T = torch.bernoulli(prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(torch.nn.Module):\n",
    "    '''\n",
    "    Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(Log_Reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(D_in, D_out, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPTW_PPS_MC(\n",
    "    X, T, prob_vec, Y, tau, alphas, reg_co, k, nf\n",
    "):\n",
    "    '''\n",
    "    average treatment effect with inverse probability of treatment weighting using private propensity scores over k-folds\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "\n",
    "    # sgd step size\n",
    "    step_size = 0.01\n",
    "\n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "\n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "\n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # get no. of points in each fold\n",
    "    nb = int(nf / k)\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack(\n",
    "        [torch.randperm(ns) for i in range(ne)]\n",
    "    )\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # create sampling indices\n",
    "    k_perm = torch.arange(nf).reshape(k, nb, 1)\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1 - T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # precompute ||X0_sl||_2^2 and ||X1_sl||_2^2\n",
    "    X0_s1_2 = (\n",
    "        X0_s1.norm(dim=2) ** 2\n",
    "    ).reshape(ne, 1, est_split)\n",
    "    X1_s1_2 = (\n",
    "        X1_s1.norm(dim=2) ** 2\n",
    "    ).reshape(ne, 1, est_split)\n",
    "\n",
    "    # add x_i to x_j for X0_plus_X0_s1 and X1_plus_X1_s1\n",
    "    X0_plus_X0_s1 = X0_s1.reshape(ne, est_split, 1, dim) + X0_s1.reshape(ne, 1, est_split, dim)\n",
    "    X1_plus_X1_s1 = X1_s1.reshape(ne, est_split, 1, dim) + X1_s1.reshape(ne, 1, est_split, dim)\n",
    "\n",
    "    # get norms squared for X0_plus_X0_s1 and X1_plus_X1_sl\n",
    "    X0_plus_X0_sl_norm_2 = (\n",
    "        X0_plus_X0_s1.norm(dim=-1) ** 2\n",
    "    ).reshape(ne, 1, est_split, est_split)\n",
    "    X1_plus_X1_sl_norm_2 = (\n",
    "        X1_plus_X1_s1.norm(dim=-1) ** 2\n",
    "    ).reshape(ne, 1, est_split, est_split)\n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits\n",
    "    Y0_s0 = Y0[idx, s0]\n",
    "    Y1_s0 = Y1[idx, s0]\n",
    "\n",
    "    Y0_s1 = Y0[idx, s1]\n",
    "    Y1_s1 = Y1[idx, s1]\n",
    "\n",
    "    # mult y_i to y_j for Y0_times_Y0_s1 and Y1_times_Y1_s1\n",
    "    Y0_times_Y0_s1 = Y0_s1.reshape(ne, 1, est_split, 1) * Y0_s1.reshape(ne, 1, 1, est_split)\n",
    "    Y1_times_Y1_s1 = Y1_s1.reshape(ne, 1, est_split, 1) * Y1_s1.reshape(ne, 1, 1, est_split)\n",
    "\n",
    "    # reshape estimate splits for later\n",
    "    Y0_s1 = Y0_s1.reshape(ne, 1, est_split)\n",
    "    Y1_s1 = Y1_s1.reshape(ne, 1, est_split)\n",
    "\n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "\n",
    "    # instantiate ne different models and set model parameters to float64\n",
    "    models = [\n",
    "        [Log_Reg(dim, 1).double() for j in range(k)]\n",
    "        for i in range(ne)\n",
    "    ]\n",
    "\n",
    "    # define loss (binary cross entropy)\n",
    "    loss = torch.nn.BCELoss()\n",
    "\n",
    "    # define optimisers\n",
    "    optimisers = [\n",
    "        [\n",
    "            torch.optim.SGD(\n",
    "                models[i][j].parameters(),\n",
    "                lr=step_size,\n",
    "                weight_decay=reg_co,\n",
    "            )\n",
    "            for j in range(k)\n",
    "        ]\n",
    "        for i in range(ne)\n",
    "    ]\n",
    "\n",
    "    # train model\n",
    "    for t in range(1000):\n",
    "        # predictions\n",
    "        preds = [\n",
    "            [\n",
    "                models[i][j](\n",
    "                    X_s0[i, k_perm[j, :].squeeze()]\n",
    "                ).squeeze()\n",
    "                for j in range(k)\n",
    "            ]\n",
    "            for i in range(ne)\n",
    "        ]\n",
    "        # losses\n",
    "        losses = [\n",
    "            [\n",
    "                loss(\n",
    "                    preds[i][j],\n",
    "                    T_s0[i, k_perm[j, :].squeeze()],\n",
    "                )\n",
    "                for j in range(k)\n",
    "            ]\n",
    "            for i in range(ne)\n",
    "        ]\n",
    "        # zero out gradients\n",
    "        [\n",
    "            [optimisers[i][j].zero_grad for j in range(k)]\n",
    "            for i in range(ne)\n",
    "        ]\n",
    "        # compute gradients\n",
    "        [\n",
    "            [losses[i][j].backward() for j in range(k)]\n",
    "            for i in range(ne)\n",
    "        ]\n",
    "        # apply gradients\n",
    "        [\n",
    "            [optimisers[i][j].step() for j in range(k)]\n",
    "            for i in range(ne)\n",
    "        ]\n",
    "\n",
    "    #############################\n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "\n",
    "    # initialise pi_hat dictionaries\n",
    "    pi_hats = {}\n",
    "    pi_hats_analytic = {}\n",
    "\n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack(\n",
    "        [\n",
    "            torch.stack(\n",
    "                [\n",
    "                    models[i][j](X_s1[i]).squeeze()\n",
    "                    for j in range(k)\n",
    "                ]\n",
    "            )\n",
    "            for i in range(ne)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # perturb model and get relevant quantities\n",
    "    for eps in alphas:\n",
    "        # define sigma\n",
    "        s_a = 2.0 / (nb * reg_co)\n",
    "\n",
    "        # moments accountant\n",
    "        sigma = s_a / eps\n",
    "        sigma_2 = sigma ** 2\n",
    "\n",
    "        # define noise distribution\n",
    "        noise_dist = torch.distributions.normal.Normal(\n",
    "            torch.tensor([0.0], dtype=torch.float64),\n",
    "            torch.tensor([sigma], dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "        # draw noise vectors\n",
    "        noise_vecs = noise_dist.sample(\n",
    "            (ne, k, dim)\n",
    "        ).squeeze()\n",
    "\n",
    "        # create temp models\n",
    "        models_ = copy.deepcopy(models)\n",
    "\n",
    "        # \\hat{\\w}^\\top Xs\n",
    "        w_T_X0_s1 = []\n",
    "        w_T_X0_plus_X0_s1 = []\n",
    "        w_T_X1_s1 = []\n",
    "        w_T_X1_plus_X1_s1 = []\n",
    "\n",
    "        # initialise list for privatised estimated propensity scores\n",
    "        pi_hats[eps] = []\n",
    "\n",
    "        # perturb weights with noise vectors\n",
    "        for i in range(ne):\n",
    "            for j in range(k):\n",
    "                w_T_X0_s1.append(\n",
    "                    torch.einsum(\n",
    "                        'ij,kj-> i',\n",
    "                        X0_s1[i],\n",
    "                        models[i][j].linear.weight,\n",
    "                    )\n",
    "                )\n",
    "                w_T_X0_plus_X0_s1.append(\n",
    "                    torch.einsum(\n",
    "                        'ijk,lk-> ij',\n",
    "                        X0_plus_X0_s1[i],\n",
    "                        models[i][j].linear.weight,\n",
    "                    )\n",
    "                )\n",
    "                w_T_X1_s1.append(\n",
    "                    torch.einsum(\n",
    "                        'ij,kj-> i',\n",
    "                        X1_s1[i],\n",
    "                        models[i][j].linear.weight,\n",
    "                    )\n",
    "                )\n",
    "                w_T_X1_plus_X1_s1.append(\n",
    "                    torch.einsum(\n",
    "                        'ijk,lk-> ij',\n",
    "                        X1_plus_X1_s1[i],\n",
    "                        models[i][j].linear.weight,\n",
    "                    )\n",
    "                )\n",
    "                # perturb weights of jth fold of ith experiment\n",
    "                model_temp = models_[i][j]\n",
    "                model_temp.linear.weight.data.add_(\n",
    "                    noise_vecs[i, j, :]\n",
    "                )\n",
    "                pi_hats[eps].append(\n",
    "                    model_temp(X_s1[i]).squeeze()\n",
    "                )\n",
    "\n",
    "        # reshape stacked privatised estimated propensity scores as ne * nd\n",
    "        pi_hats[eps] = torch.stack(pi_hats[eps]).reshape(\n",
    "            ne, k, est_split\n",
    "        )\n",
    "\n",
    "        # precompute sigma^2 ||x||_2^2 and \\w^\\top Xs\n",
    "        pi_hats_analytic[eps] = {'sigma_2_X0_s1_2': sigma_2 * X0_s1_2}\n",
    "        pi_hats_analytic[eps]['sigma_2_X1_s1_2'] = sigma_2 * X1_s1_2\n",
    "        pi_hats_analytic[eps]['sigma_2_X0_plus_X0_s1'] = sigma_2 * X0_plus_X0_sl_norm_2\n",
    "        pi_hats_analytic[eps]['sigma_2_X1_plus_X1_s1'] = sigma_2 * X1_plus_X1_sl_norm_2\n",
    "        pi_hats_analytic[eps]['w_T_X0_s1'] = torch.stack(\n",
    "            w_T_X0_s1\n",
    "        ).reshape(ne, k, est_split)\n",
    "        pi_hats_analytic[eps]['w_T_X0_plus_X0_s1'] = torch.stack(\n",
    "            w_T_X0_plus_X0_s1\n",
    "        ).reshape(ne, k, est_split, est_split)\n",
    "        pi_hats_analytic[eps]['w_T_X1_s1'] = torch.stack(\n",
    "            w_T_X1_s1\n",
    "        ).reshape(ne, k, est_split)\n",
    "        pi_hats_analytic[eps]['w_T_X1_plus_X1_s1'] = torch.stack(\n",
    "            w_T_X1_plus_X1_s1\n",
    "        ).reshape(ne, k, est_split, est_split)\n",
    "\n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and stds of means of ERM + noise\n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # analytic means and stds of ERM + noise\n",
    "    te_hats_analytic = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(\n",
    "        Y1_s1.squeeze() / prob_vec[idx, s1] - Y0_s1.squeeze() / (1 - prob_vec[idx, s1]),\n",
    "        1,\n",
    "    )\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "\n",
    "    for key in pi_hats.keys():\n",
    "        # empirical estimates\n",
    "        # reduce_mean from (ne, k, est_split) tensor to (ne * nd, 1) matrix\n",
    "        te_hats_ = torch.mean(\n",
    "            Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]),\n",
    "            2,\n",
    "        )\n",
    "        te_hats['means'].append(\n",
    "            [\n",
    "                te_hats_[i].mean().detach().numpy()\n",
    "                for i in range(ne)\n",
    "            ]\n",
    "        )\n",
    "        te_hats['stds'].append(\n",
    "            [\n",
    "                te_hats_[i].std().detach().numpy()\n",
    "                for i in range(ne)\n",
    "            ]\n",
    "        )\n",
    "        if key != 0:\n",
    "            # analytic estimates\n",
    "            # expectation and variance of mu_0\n",
    "            rand_mu_0 = Y0_s1 * torch.exp(\n",
    "                pi_hats_analytic[key]['w_T_X0_s1'] + pi_hats_analytic[key]['sigma_2_X0_s1_2'] / 2\n",
    "            )\n",
    "            E_mu_0 = torch.mean(Y0_s1 + rand_mu_0, [2])\n",
    "            mu_X0_s1_2 = Y0_times_Y0_s1 * torch.exp(\n",
    "                pi_hats_analytic[key]['w_T_X0_plus_X0_s1'] + pi_hats_analytic[key]['sigma_2_X0_plus_X0_s1'] / 2\n",
    "            )\n",
    "            mu_X0_s1_mu_X0_s1 = rand_mu_0.reshape(ne, k, 1, est_split) * rand_mu_0.reshape(ne, k, est_split, 1)\n",
    "            var_mu_0 = torch.mean(\n",
    "                mu_X0_s1_2 - mu_X0_s1_mu_X0_s1, \n",
    "                [2, 3]\n",
    "            )\n",
    "            # expectation and variance of mu_1\n",
    "            rand_mu_1 = Y1_s1 * torch.exp(\n",
    "                - (pi_hats_analytic[key]['w_T_X1_s1'] + pi_hats_analytic[key]['sigma_2_X1_s1_2'] / 2)\n",
    "            )\n",
    "            E_mu_1 = torch.mean(Y1_s1 + rand_mu_1, [2])\n",
    "            mu_X1_s1_2 = Y1_times_Y1_s1 * torch.exp(\n",
    "                - (pi_hats_analytic[key]['w_T_X1_plus_X1_s1'] + pi_hats_analytic[key]['sigma_2_X1_plus_X1_s1'] / 2)\n",
    "            )\n",
    "            mu_X1_s1_mu_X1_s1 = rand_mu_1.reshape(ne, k, 1, est_split) * rand_mu_1.reshape(ne, k, est_split, 1)\n",
    "            var_mu_1 = torch.mean(\n",
    "                mu_X1_s1_2 - mu_X1_s1_mu_X1_s1, \n",
    "                [2, 3]\n",
    "            )\n",
    "            # expectation and variance of te_hats\n",
    "            te_hats_analytic_mu = E_mu_1 - E_mu_0\n",
    "            te_hats_analytic_std = torch.sqrt(\n",
    "                var_mu_1 + var_mu_0\n",
    "            )\n",
    "            te_hats_analytic['means'].append(\n",
    "                [\n",
    "                    te_hats_analytic_mu[i]\n",
    "                    .mean()\n",
    "                    .detach()\n",
    "                    .numpy()\n",
    "                    for i in range(ne)\n",
    "                ]\n",
    "            )\n",
    "            te_hats_analytic['stds'].append(\n",
    "                [\n",
    "                    te_hats_analytic_std[i]\n",
    "                    .mean()\n",
    "                    .detach()\n",
    "                    .numpy()\n",
    "                    for i in range(ne)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_analytic['means'] = np.array(te_hats_analytic['means'])\n",
    "    te_hats_analytic['stds'] = np.array(te_hats_analytic['stds'])\n",
    "\n",
    "    return te, te_hats, te_hats_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname, tau, te_hats, epses, ne):\n",
    "    '''\n",
    "    plot histogram of empirical probabilities of signs flipping for \\hat{\\tau} and \\hat{\\tau}_\\epsilon\n",
    "    '''\n",
    "    \n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats['means'][1:])):\n",
    "        te_hats['means'][1:][i][\n",
    "            np.isnan(te_hats['means'][1:][i])\n",
    "        ] = -tau\n",
    "\n",
    "    sgn_tau_hat = np.sign(te_hats['means'][0])\n",
    "\n",
    "    # compute probabilities\n",
    "    probs = [\n",
    "        sum(np.sign(i) != sgn_tau_hat) / ne\n",
    "        for i in te_hats['means'][1:]\n",
    "    ]\n",
    "    \n",
    "    # convert epses to strings\n",
    "    str_epses = [str(i) for i in epses]\n",
    "\n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 5))\n",
    "    ax.bar(str_epses, probs)\n",
    "\n",
    "    y_name = \"P(sgn($\\\\hat{\\\\tau}$) $\\\\neq$ sgn($\\\\hat{\\\\tau}_\\\\epsilon$))\"\n",
    "    \n",
    "    ax.set_title(\n",
    "        y_name\n",
    "        + \"against $\\epsilon$ for $\\\\tau$ = {}\".format(tau),\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_ylabel(y_name, fontsize=18)\n",
    "    ax.set_xlabel(\"privacy loss ($\\epsilon$)\", fontsize=18)\n",
    "    \n",
    "    ax.tick_params(labelsize=16)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.pdf',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\tau = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "te, te_hats, te_hats_analytic = IPTW_PPS_MC(X, T, prob_vec, Y, tau, alphas, reg_co, k, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_mc_tau_'+str(tau)+'_alpha_flip_prob', tau, te_hats, epses, ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
