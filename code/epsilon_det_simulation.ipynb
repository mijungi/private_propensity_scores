{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of $\\epsilon$ on Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1067dd970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from agm import calibrateAnalyticGaussianMechanism\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. experiments, no. draws of z, no. samples, dim, X\n",
    "ne = 100\n",
    "nd = 1\n",
    "ns = 1200\n",
    "dim = 50\n",
    "\n",
    "# draw ne separate ns samples\n",
    "X_std = 3\n",
    "X_dist = torch.distributions.normal.Normal(torch.tensor([0.0], dtype=torch.float64), torch.tensor([X_std], dtype=torch.float64))\n",
    "X  = [X_dist.sample((ns, dim)).squeeze() for i in range(ne)]\n",
    "\n",
    "# restrict X to ||x||_2 \\leq 1 to fit assumption for each experiment\n",
    "X = torch.stack([X[i] / X[i].norm(dim=1).max() for i in range(ne)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of points used to fit log reg\n",
    "nf = 1000\n",
    "\n",
    "# privacy parameters\n",
    "epses = [0.01, 0.03, 0.05, 0.1, 0.2, 0.4, 0.8, 0.99]\n",
    "delta = 1e-6\n",
    "\n",
    "# regularisation coefficient\n",
    "reg_co = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating Y, differentiate between Y_0 and Y_1 with true treatment effect tau\n",
    "# Y = beta^T X + 0.1 Z\n",
    "# Y_1 = Y + tau, Y_0 = Y\n",
    "beta_std = 1\n",
    "beta_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0], dtype=torch.float64), torch.tensor([beta_std], dtype=torch.float64))\n",
    "beta = beta_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "\n",
    "# tau\n",
    "tau = 2\n",
    "\n",
    "# generate Y\n",
    "Y_std = 0.1\n",
    "Y = torch.einsum('kl,ijk->ij',beta,X) + Y_std * torch.randn(ne, ns, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for generating T\n",
    "# T = exp(-T_w^T X + b)\n",
    "T_std = 1\n",
    "T_dist = torch.distributions.normal.Normal(\n",
    "    torch.tensor([0.0], dtype=torch.float64), torch.tensor([T_std], dtype=torch.float64))\n",
    "T_w = T_dist.sample((dim, 1)).reshape(dim, 1)\n",
    "T_b = 0\n",
    "\n",
    "# generate T\n",
    "prob_vec = torch.sigmoid(torch.einsum('kl,ijk->ij', T_w, X) + T_b)\n",
    "T = torch.bernoulli(prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(torch.nn.Module):\n",
    "    '''\n",
    "    Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(Log_Reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(D_in, D_out, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPTW_PPS(X, T, prob_vec, Y, tau, epses, delta, reg_co, nd, nf):\n",
    "    '''\n",
    "    average treatment effect with inverse probability of treatment weighting using private propensity scores\n",
    "    '''\n",
    "    # get # experiments, # samples, # dimensions\n",
    "    ne, ns, dim = X.shape\n",
    "    \n",
    "    # sgd step size\n",
    "    step_size = 0.01\n",
    "    \n",
    "    ################\n",
    "    # process data #\n",
    "    ################\n",
    "    \n",
    "    # get Y0 and Y1\n",
    "    Y0 = Y * (1 - T)\n",
    "    Y1 = (Y + tau) * T\n",
    "    \n",
    "    # split data\n",
    "    # get splits\n",
    "    fit_split = nf\n",
    "    est_split = ns - nf\n",
    "\n",
    "    # permute indices\n",
    "    perm = torch.stack([torch.randperm(ns) for i in range(ne)])\n",
    "\n",
    "    # create splits\n",
    "    s0 = perm[:, :fit_split]\n",
    "    s1 = perm[:, fit_split:]\n",
    "\n",
    "    # create auxiliary indices\n",
    "    idx = torch.arange(ne)[:, None]\n",
    "\n",
    "    # split X into fit, estimate splits\n",
    "    X_s0 = X[idx, s0]\n",
    "    X_s1 = X[idx, s1]\n",
    "\n",
    "    # expand dim of T to allow multiplication with X\n",
    "    T_ex_dim = T.reshape(ne, ns, 1)\n",
    "\n",
    "    # split X0 and X1 into fit, estimate splits\n",
    "    X0_s1 = (X * (1- T_ex_dim))[idx, s1]\n",
    "    X1_s1 = (X * T_ex_dim)[idx, s1]\n",
    "\n",
    "    # precompute ||X0_sl||_2^2 and ||X1_sl||_2^2\n",
    "    X0_s1_2 = X0_s1.norm(dim=2) ** 2\n",
    "    X1_s1_2 = X1_s1.norm(dim=2) ** 2\n",
    "\n",
    "    # add x_i to x_j for X0_plus_X0_s1 and X1_plus_X1_s1\n",
    "    X0_plus_X0_s1 = X0_s1.reshape(ne, est_split, 1, dim) + X0_s1.reshape(ne, 1, est_split, dim)\n",
    "    X1_plus_X1_s1 = X1_s1.reshape(ne, est_split, 1, dim) + X1_s1.reshape(ne, 1, est_split, dim)\n",
    "\n",
    "    # get norms squared for X0_plus_X0_s1 and X1_plus_X1_sl\n",
    "    X0_plus_X0_sl_norm_2 = X0_plus_X0_s1.norm(dim=-1) ** 2 \n",
    "    X1_plus_X1_sl_norm_2 = X1_plus_X1_s1.norm(dim=-1) ** 2 \n",
    "\n",
    "    # split T into fit, estimate splits\n",
    "    T_s0 = T[idx, s0]\n",
    "    T_s1 = T[idx, s1]\n",
    "\n",
    "    # split Y0 and Y1 into fit, estimate splits \n",
    "    Y0_s0 = Y0[idx, s0] \n",
    "    Y1_s0 = Y1[idx, s0] \n",
    "\n",
    "    Y0_s1 = Y0[idx, s1] \n",
    "    Y1_s1 = Y1[idx, s1] \n",
    "\n",
    "    # mult y_i to y_j for Y0_times_Y0_s1 and Y1_times_Y1_s1\n",
    "    Y0_times_Y0_s1 = Y0_s1.reshape(ne, est_split, 1) * Y0_s1.reshape(ne, 1, est_split)\n",
    "    Y1_times_Y1_s1 = Y1_s1.reshape(ne, est_split, 1) * Y1_s1.reshape(ne, 1, est_split)\n",
    "    \n",
    "    # reshape estimate splits for later\n",
    "    Y0_s1 = Y0_s1.reshape(ne, 1, est_split)\n",
    "    Y1_s1 = Y1_s1.reshape(ne, 1, est_split)\n",
    "    \n",
    "    ##############\n",
    "    # fit models #\n",
    "    ##############\n",
    "\n",
    "    # instantiate ne different models\n",
    "    models = [Log_Reg(dim, 1) for i in range(ne)]\n",
    "    # set model parameters to float64\n",
    "    [model.double() for model in models]\n",
    "\n",
    "    # define loss (binary cross entropy)\n",
    "    loss = torch.nn.BCELoss()\n",
    "\n",
    "    # define optimisers\n",
    "    optimisers = [torch.optim.SGD(models[i].parameters(), lr=step_size, weight_decay=reg_co) for i in range(ne)]\n",
    "    \n",
    "    # train models\n",
    "    for t in range(1000):\n",
    "        preds = [models[i](X_s0[i]).squeeze() for i in range(ne)]\n",
    "        losses = [loss(preds[i], T_s0[i]) for i in range(ne)]\n",
    "        [opt.zero_grad for opt in optimisers]\n",
    "        [loss.backward() for loss in losses]\n",
    "        [opt.step() for opt in optimisers]  \n",
    "        \n",
    "    #############################    \n",
    "    # estimate treatment effect #\n",
    "    #############################\n",
    "    \n",
    "    # initialise pi_hat dictionaries \n",
    "    pi_hats = {} \n",
    "    pi_hats_analytic = {}\n",
    "    \n",
    "    # get estimated propensity scores\n",
    "    pi_hats[0] = torch.stack([models[i](X_s1[i]).squeeze() for i in range(ne)])\n",
    "\n",
    "    # perturb model and get relevant quantities\n",
    "    for eps in epses:\n",
    "        # define sigma\n",
    "        s_a = 2. / (fit_split * reg_co)\n",
    "\n",
    "        # gaussian mechanism\n",
    "        sigma = np.sqrt(2 * np.log(1.25 / delta) + 1e-10) *  (s_a  / eps)\n",
    "        sigma_2 = sigma ** 2\n",
    "\n",
    "        # # analytic gaussian mechanism\n",
    "        # sigma = calibrateAnalyticGaussianMechanism(eps, delta, s_a)\n",
    "        # sigma_2 = sigma ** 2\n",
    "\n",
    "        # define noise distribution\n",
    "        noise_dist = torch.distributions.normal.Normal(torch.tensor([0.0], dtype=torch.float64), torch.tensor([sigma], dtype=torch.float64))\n",
    "\n",
    "        # draw noise vectors\n",
    "        noise_vecs = noise_dist.sample((ne, nd, dim)).reshape(ne, nd, dim)\n",
    "        \n",
    "        # create temp models \n",
    "        models_ = [copy.deepcopy(models) for i in range(nd)]\n",
    "        \n",
    "        # \\hat{\\w}^\\top Xs\n",
    "        w_T_X0_s1 = []\n",
    "        w_T_X0_plus_X0_s1 = []\n",
    "        w_T_X1_s1 = []\n",
    "        w_T_X1_plus_X1_s1 = []\n",
    "\n",
    "        # initialise list for privatised estimated propensity scores\n",
    "        pi_hats[eps] = []\n",
    "        \n",
    "        # perturb weights with noise vectors\n",
    "        for i in range(ne):\n",
    "            w_T_X0_s1.append(torch.einsum('ij,kj-> i', X0_s1[i], models[i].linear.weight))\n",
    "            w_T_X0_plus_X0_s1.append(torch.einsum('ijk,lk-> ij', X0_plus_X0_s1[i], models[i].linear.weight))\n",
    "            w_T_X1_s1.append(torch.einsum('ij,kj-> i', X1_s1[i], models[i].linear.weight))\n",
    "            w_T_X1_plus_X1_s1.append(torch.einsum('ijk,lk-> ij', X1_plus_X1_s1[i], models[i].linear.weight))\n",
    "            for j in range(nd):\n",
    "                model_temp = models_[j][i]\n",
    "                model_temp.linear.weight.data.add_(noise_vecs[i, j, :])\n",
    "                pi_hats[eps].append(model_temp(X_s1[i]).squeeze())\n",
    "                \n",
    "        # reshape stacked privatised estimated propensity scores as ne * nd\n",
    "        pi_hats[eps] = torch.stack(pi_hats[eps]).reshape(ne, nd, est_split)\n",
    "        \n",
    "        # precompute sigma^2 ||x||_2^2 and \\w^\\top Xs\n",
    "        pi_hats_analytic[eps] = {'sigma_2_X0_s1_2': sigma_2 * X0_s1_2}\n",
    "        pi_hats_analytic[eps]['sigma_2_X1_s1_2'] = sigma_2 * X1_s1_2\n",
    "        pi_hats_analytic[eps]['sigma_2_X0_plus_X0_s1'] = sigma_2 * X0_plus_X0_sl_norm_2\n",
    "        pi_hats_analytic[eps]['sigma_2_X1_plus_X1_s1'] = sigma_2 * X1_plus_X1_sl_norm_2\n",
    "        pi_hats_analytic[eps]['w_T_X0_s1'] = torch.stack(w_T_X0_s1)\n",
    "        pi_hats_analytic[eps]['w_T_X0_plus_X0_s1'] = torch.stack(w_T_X0_plus_X0_s1)\n",
    "        pi_hats_analytic[eps]['w_T_X1_s1'] = torch.stack(w_T_X1_s1)\n",
    "        pi_hats_analytic[eps]['w_T_X1_plus_X1_s1'] = torch.stack(w_T_X1_plus_X1_s1)\n",
    "                \n",
    "    # get treatment effects\n",
    "    # true\n",
    "    te = {}\n",
    "    # empirical means and (std of means) of ERM + private ERM \n",
    "    te_hats = {'means': [], 'stds': []}\n",
    "    # analytic means and (std of means + mean of stds) of private ERM\n",
    "    te_hats_analytic = {'means': [], 'stds': []}\n",
    "\n",
    "    # estimate true treatment effect\n",
    "    te_ = torch.mean(Y1_s1.squeeze() / prob_vec[idx, s1] - Y0_s1.squeeze() / (1 - prob_vec[idx, s1]), 1)\n",
    "    te['mean'] = te_.mean().detach().numpy()\n",
    "    te['std'] = te_.std().detach().numpy()\n",
    "\n",
    "    for key in pi_hats.keys():\n",
    "        if key != 0:\n",
    "            # empirical estimates\n",
    "            # reduce_mean from (ne, nd, est_split) tensor to (ne * nd, 1) matrix\n",
    "            te_hats_ = torch.mean(Y1_s1 / pi_hats[key] - Y0_s1 / (1 - pi_hats[key]), 2)\n",
    "            # analytic estimates\n",
    "            # expectation and variance of mu_0\n",
    "            rand_mu_0 = Y0_s1.squeeze() * torch.exp(pi_hats_analytic[key]['w_T_X0_s1'] + pi_hats_analytic[key]['sigma_2_X0_s1_2']/2)\n",
    "            E_mu_0 = torch.mean(Y0_s1.squeeze() + rand_mu_0, [1])\n",
    "            mu_X0_s1_2 = Y0_times_Y0_s1 * torch.exp(pi_hats_analytic[key]['w_T_X0_plus_X0_s1'] + pi_hats_analytic[key]['sigma_2_X0_plus_X0_s1']/2)\n",
    "            mu_X0_s1_mu_X0_s1 = rand_mu_0.reshape(ne, 1, est_split) * rand_mu_0.reshape(ne, est_split, 1)\n",
    "            var_mu_0 = torch.mean(mu_X0_s1_2 - mu_X0_s1_mu_X0_s1, [1, 2])\n",
    "            # expectation and variance of mu_1\n",
    "            rand_mu_1 = Y1_s1.squeeze() * torch.exp(- pi_hats_analytic[key]['w_T_X1_s1'] + pi_hats_analytic[key]['sigma_2_X1_s1_2']/2)\n",
    "            E_mu_1 = torch.mean(Y1_s1.squeeze() + rand_mu_1, [1])\n",
    "            mu_X1_s1_2 = Y1_times_Y1_s1 * torch.exp(- pi_hats_analytic[key]['w_T_X1_plus_X1_s1'] + pi_hats_analytic[key]['sigma_2_X1_plus_X1_s1']/2)\n",
    "            mu_X1_s1_mu_X1_s1 = rand_mu_1.reshape(ne, 1, est_split) * rand_mu_1.reshape(ne, est_split, 1)\n",
    "            var_mu_1 = torch.mean(mu_X1_s1_2 - mu_X1_s1_mu_X1_s1, [1, 2])\n",
    "            # expectation and variance of te_hats\n",
    "            te_hats_analytic_mu = E_mu_1 - E_mu_0\n",
    "            te_hats_analytic_std = torch.sqrt(var_mu_1 + var_mu_0)\n",
    "            te_hats_analytic['means'].append(te_hats_analytic_mu.detach().numpy())\n",
    "            te_hats_analytic['stds'].append(te_hats_analytic_std.detach().numpy())\n",
    "        else:\n",
    "            # empirical estimate for noiseless case\n",
    "            # reduce_mean from (ne, est_split) tensor to (ne , 1) matrix\n",
    "            te_hats_ = torch.mean(Y1_s1.squeeze() / pi_hats[key] - Y0_s1.squeeze() / (1 - pi_hats[key]), 1).reshape(ne, 1)\n",
    "        te_hats['means'].append([te_hats_[i].mean().detach().numpy() for i in range(ne)])\n",
    "        te_hats['stds'].append([te_hats_[i].std().detach().numpy() for i in range(ne)])            \n",
    "    \n",
    "    te_hats['means'] = np.array(te_hats['means'])\n",
    "    te_hats['stds'] = np.array(te_hats['stds'])\n",
    "    te_hats_analytic['means'] = np.array(te_hats_analytic['means'])\n",
    "    te_hats_analytic['stds'] = np.array(te_hats_analytic['stds'])\n",
    "    \n",
    "    return te, te_hats, te_hats_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname, tau, te_hats, var, ne):\n",
    "    '''\n",
    "    plot histogram of empirical probabilities flipped signs \n",
    "    '''\n",
    "    \n",
    "    # deal with nans by setting them to be -bias\n",
    "    for i in range(len(te_hats['means'][1:])):\n",
    "        te_hats['means'][1:][i][np.isnan(te_hats['means'][1:][i])] = -tau     \n",
    "    \n",
    "    sgn_tau_hat = np.sign(te_hats['means'][0])\n",
    "    \n",
    "    # compute probabilities\n",
    "    probs = [sum(np.sign(i) != sgn_tau_hat) / ne for i in te_hats['means'][1:]]    \n",
    "    str_var = [str(i) for i in var]\n",
    "    \n",
    "    print(probs)\n",
    "    print(str_var)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 5))\n",
    "    ax.bar(str_var, probs)\n",
    "\n",
    "    title = \"(sgn(\"+\"$\\\\hat{\\\\tau}$\"+\")\"+\"$\\\\neq$\"+\"sgn(\"+\"$\\\\hat{\\\\tau}_\\\\epsilon$\" + \"))\"\n",
    "    \n",
    "    ax.set_title(\"P\"+title+\" against $\\epsilon$ for $\\\\tau$ = {}\".format(bias), fontsize=20)\n",
    "    ax.set_ylabel(\"P\"+title, fontsize=18)\n",
    "    ax.set_xlabel(\"privacy loss ($\\epsilon$)\", fontsize=18)\n",
    "    \n",
    "    ax.tick_params(labelsize=16)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.pdf',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_te(figname, te, te_hats, te_hats_analytic, epses, cutoff, tau):\n",
    "    '''\n",
    "    plot the true treatment effect, ERM, private ERM treatment effect\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1,1, figsize=(20, 10))\n",
    "    \n",
    "    te_hat = np.mean([te_hats['means'][0]], 1)\n",
    "    te_hat_std = np.std([te_hats['means'][0]])\n",
    "    te_hat_z = np.mean(te_hats['means'][1:], 1)[cutoff:]\n",
    "    te_hat_z_std = np.std(te_hats['means'][1:], 1)[cutoff:]\n",
    "    te_hat_mu = np.mean(te_hats_analytic['means'], 1)[cutoff:]\n",
    "    te_hat_mu_std = np.std(te_hats_analytic['means'], 1)[cutoff:] + np.mean(te_hats_analytic['stds'], 1)[cutoff:]\n",
    "    \n",
    "    ax.plot(epses[cutoff:], [te['mean']] * len(epses[cutoff:]) , marker='o', color='magenta', label=\"Truth\")\n",
    "#     ax.fill_between(epses, te['mean'] + te['std'], te['mean'] - te['std'], facecolor='magenta', alpha=0.25)\n",
    "    ax.plot(epses[cutoff:], [te_hat] * len(epses[cutoff:]) , marker='o', color='red', label=\"ERM\")\n",
    "    ax.plot(epses[cutoff:], te_hat_z, marker='x', color='blue', label=\"Empirical Private ERM\")\n",
    "    ax.plot(epses[cutoff:], te_hat_mu ,marker='d', color='green', label=\"Analytical Private ERM\")\n",
    "    ax.fill_between(epses[cutoff:], te_hat + te_hat_std, \n",
    "                        te_hat - te_hat_std, facecolor='red', alpha=0.25)\n",
    "    ax.fill_between(epses[cutoff:], te_hat_z + te_hat_z_std, \n",
    "                        te_hat_z - te_hat_z_std, facecolor='blue', alpha=0.25)\n",
    "    ax.fill_between(epses[cutoff:], te_hat_mu + te_hat_mu_std,\n",
    "                        te_hat_mu - te_hat_mu_std, facecolor='green', alpha=0.25)\n",
    "\n",
    "    ax.set_title(\"True, ERM, Empirical Private ERM and Analytical Private ERM ATE against $\\epsilon$\", fontsize=20)\n",
    "    ax.set_ylabel(\"Average Treatment Effect\", fontsize=20)\n",
    "    ax.set_xlabel(\"$\\epsilon$\", fontsize=20)\n",
    "    if tau > 0:\n",
    "        ax.legend(fontsize=16, loc=1)\n",
    "    else:\n",
    "        ax.legend(fontsize=16, loc=4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figname+'.png',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model I $(\\mathbb{E}[\\mu_1 - \\mu_0] = 0)$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generate T \\in {0, 1}\n",
    "prob_vec = 0.5 * torch.ones(ne, ns, dtype=torch.float64)\n",
    "T = torch.bernoulli(prob_vec)\n",
    "\n",
    "# get Y0 and Y1\n",
    "Y0 = Y * (1 - T)\n",
    "Y1 = (Y + 0) * T    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the true functions and the samples\n",
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(Y0[0, :][Y0[0, :].nonzero()].squeeze().numpy(),linewidth=1,linestyle=\"None\",marker='o',color='red',label=\"Y_0\")\n",
    "ax.plot(Y1[0, :][Y1[0, :].nonzero()].squeeze().numpy(),linewidth=1,linestyle=\"None\",marker='x',color='blue',label=\"Y_1\")\n",
    "ax.legend([\"$Y_0$\",\"$Y_1$\"])\n",
    "ax.set_title(\"Scenario I\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('data_scenario_1.png',dpi=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the histograms\n",
    "fig, ax = plt.subplots(1,1)\n",
    "n, bins, patches = ax.hist(Y0[0, :][Y0[0, :].nonzero()].squeeze().numpy(),30,density=1,facecolor='green', alpha=0.6, label=\"$Y_0$\")\n",
    "# y0 = mlab.normpdf(bins, 0, 1)\n",
    "# l = plt.plot(bins, y0, 'r--', linewidth=3,label='Y0')\n",
    "\n",
    "n, bins, patches = ax.hist(Y1[0, :][Y1[0, :].nonzero()].squeeze().numpy(),30,density=1,facecolor='blue', alpha=0.6,label=\"$Y_1$\")\n",
    "# y1 = mlab.normpdf(bins, 2, 1)\n",
    "# l = plt.plot(bins, y1, 'm--', linewidth=3,label='Y1')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Scenario I', fontsize=16)\n",
    "ax.set_ylabel('P(Y)', fontsize=16)\n",
    "ax.set_xlabel('Y', fontsize=16)\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('data_model_1.png',dpi=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "te, te_hats, te_hats_analytic, flipped = IPTW_PPS(X, T, prob_vec, Y, 0, epses, delta, reg_co, nd, nf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_te('sim_bias_0_epses', te, te_hats, te_hats_analytic, epses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model II $(\\mathbb{E}[\\mu_1 - \\mu_0] = 2)$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generate T \\in {0, 1}\n",
    "# bias_sample = 2 * torch.bernoulli(0.5 * torch.ones(ne, ns, dtype=torch.float64)) - 1\n",
    "\n",
    "# get Y0 and Y1\n",
    "Y0 = Y * (1 - T)\n",
    "Y1 = (Y + bias) * T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the true functions and the samples\n",
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(Y0[0, :][Y0[0, :].nonzero()].squeeze().numpy(),linewidth=1,linestyle=\"None\",marker='o',color='red',label=\"Y_0\")\n",
    "ax.plot(Y1[0, :][Y1[0, :].nonzero()].squeeze().numpy(),linewidth=1,linestyle=\"None\",marker='x',color='blue',label=\"Y_1\")\n",
    "ax.legend([\"$Y_0$\",\"$Y_1$\"])\n",
    "ax.set_title(\"Scenario II\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('data_scenario_2.png', dpi=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the histograms\n",
    "fig, ax = plt.subplots(1,1)\n",
    "n, bins, patches = ax.hist(Y0[0, :][Y0[0, :].nonzero()].squeeze().numpy(),30,density=1,facecolor='green', alpha=0.6, label=\"$Y_0$\")\n",
    "# y0 = mlab.normpdf(bins, 0, 1)\n",
    "# l = plt.plot(bins, y0, 'r--', linewidth=3,label='Y0')\n",
    "\n",
    "n, bins, patches = ax.hist(Y1[0, :][Y1[0, :].nonzero()].squeeze().numpy(),30,density=1,facecolor='blue', alpha=0.6,label=\"$Y_1$\")\n",
    "# y1 = mlab.normpdf(bins, 2, 1)\n",
    "# l = plt.plot(bins, y1, 'm--', linewidth=3,label='Y1')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Scenario II', fontsize=16)\n",
    "ax.set_ylabel('P(Y)', fontsize=16)\n",
    "ax.set_xlabel('Y', fontsize=16)\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('data_model_2.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0239, dtype=torch.float64) tensor(1.0244, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "te, te_hats, te_hats_analytic = IPTW_PPS(X, T, prob_vec, Y, bias, epses, delta, reg_co, nd, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24, 0.03, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "['0.01', '0.03', '0.05', '0.1', '0.2', '0.4', '0.8', '0.99']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist('sim_bias_'+str(bias)+'_epses_flip_prob', bias, te_hats, epses, ne)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_te('sim_bias_'+str(bias)+'_epses', te, te_hats, te_hats_analytic, epses, 2, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model III $(\\mathbb{E}[\\mu_1 - \\mu_0] = -2)$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the true functions and the samples\n",
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(Y0[0, :][Y0[0, :].nonzero()].squeeze().numpy(),linewidth=1,linestyle=\"None\",marker='o',color='red',label=\"Y_0\")\n",
    "ax.plot(Y1[0, :][Y1[0, :].nonzero()].squeeze().numpy(),linewidth=1,linestyle=\"None\",marker='x',color='blue',label=\"Y_1\")\n",
    "ax.legend([\"$Y_0$\",\"$Y_1$\"])\n",
    "ax.set_title(\"Scenario III\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('data_scenario_3.png', dpi=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the histograms\n",
    "fig, ax = plt.subplots(1,1)\n",
    "n, bins, patches = ax.hist(Y0[0, :][Y0[0, :].nonzero()].squeeze().numpy(),30,density=1,facecolor='green', alpha=0.6, label=\"$Y_0$\")\n",
    "# y0 = mlab.normpdf(bins, 0, 1)\n",
    "# l = plt.plot(bins, y0, 'r--', linewidth=3,label='Y0')\n",
    "\n",
    "n, bins, patches = ax.hist(Y1[0, :][Y1[0, :].nonzero()].squeeze().numpy(),30,density=1,facecolor='blue', alpha=0.6,label=\"$Y_1$\")\n",
    "# y1 = mlab.normpdf(bins, 2, 1)\n",
    "# l = plt.plot(bins, y1, 'm--', linewidth=3,label='Y1')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Scenario III', fontsize=16)\n",
    "ax.set_ylabel('P(Y)', fontsize=16)\n",
    "ax.set_xlabel('Y', fontsize=16)\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('data_model_3.png', dpi=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "te, te_hats, te_hats_analytic = IPTW_PPS(X, T, prob_vec, Y, -bias, epses, delta, reg_co, nd, nf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_hist('sim_bias_'+str(-bias)+'_epses_flip_prob', -bias, te_hats, epses, ne)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_te('sim_bias_'+str(-bias)+'_epses', te, te_hats, te_hats_analytic, epses, 2, -bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
